"""
End-to-End Pipeline Test: Seoul National University (SNU)

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ìŒì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤:
1. âœ… ì„œìš¸ëŒ€ ë°ì´í„° í¬ë¡¤ë§
2. âœ… ê³„ì¸µ êµ¬ì¡° (ëŒ€í•™ â†’ ë‹¨ê³¼ëŒ€í•™ â†’ ì „ê³µ â†’ êµìˆ˜ â†’ ì—°êµ¬ì‹¤)
3. âœ… ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
4. âœ… API ì¡°íšŒ (ê³„ì¸µì  ë„¤ë¹„ê²Œì´ì…˜)
5. âœ… LLM ë¶„ì„
6. âœ… ë²¡í„° ì €ì¥ì†Œ ì—°ë™

ì‹¤í–‰: python test_e2e_snu_pipeline.py
"""

import asyncio
import json
from datetime import datetime
from typing import List, Dict, Any
import uuid

# SQLAlchemy
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from sqlalchemy.pool import StaticPool

# Domain
from src.domain.models import (
    Base, University, College, Department, Professor, Laboratory,
    LabMember, ResearchPaper, PaperAnalysis, UniversityTier, UserRole, LabMemberRole
)

# Services
from src.services.snu_crawler import SNUCrawler

# Mock LLM (ì‹¤ì œ Ollama í•„ìš” ì—†ì´ í…ŒìŠ¤íŠ¸)
class MockLLM:
    async def analyze(self, content: str):
        return {"summary": "Mock analysis result"}

# Mock VectorStore (ì‹¤ì œ ChromaDB í•„ìš” ì—†ì´ í…ŒìŠ¤íŠ¸)
class MockVectorStore:
    def __init__(self):
        self.embeddings = {}

    def add_embedding(self, paper_id: str, content: str, metadata: dict):
        self.embeddings[paper_id] = {"content": content, "metadata": metadata}

    def search(self, query: str, k: int = 5, threshold: float = 0.5):
        # ëª¨ë“  ì„ë² ë”©ì„ ê²°ê³¼ë¡œ ë°˜í™˜ (ì‹¤ì œ ìœ ì‚¬ë„ ê³„ì‚° ì—†ìŒ)
        results = []
        for paper_id, data in self.embeddings.items():
            results.append({
                "paper_id": paper_id,
                "distance": 0.85 + (len(results) * 0.05),  # ì‹œë®¬ë ˆì´ì…˜
                "metadata": data["metadata"]
            })
        return results[:k]

# Logging
from src.core.logging import get_logger, setup_logging

logger = get_logger(__name__)

# ==================== ì„¤ì • ====================

# í…ŒìŠ¤íŠ¸ìš© ì¸ë©”ëª¨ë¦¬ SQLite
TEST_DATABASE_URL = "sqlite:///:memory:"

class E2EPipeline:
    """End-to-End íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤í„°"""

    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.engine = None
        self.session = None
        self.crawler = SNUCrawler()
        self.llm = MockLLM()  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš© Mock (OllamaLLMì€ ëŠë¦¼)
        self.vector_store = MockVectorStore()  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš© Mock

    def setup_database(self):
        """í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •"""
        logger.info("ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ì¤‘...")

        self.engine = create_engine(
            TEST_DATABASE_URL,
            connect_args={"check_same_thread": False},
            poolclass=StaticPool
        )

        # í…Œì´ë¸” ìƒì„±
        Base.metadata.create_all(bind=self.engine)

        # ì„¸ì…˜ ìƒì„±
        SessionLocal = sessionmaker(bind=self.engine)
        self.session = SessionLocal()

        logger.info("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì¤€ë¹„ ì™„ë£Œ")

    def create_snu_hierarchy(self):
        """ì„œìš¸ëŒ€ ê³„ì¸µ êµ¬ì¡° ìƒì„±"""
        logger.info("\n" + "="*60)
        logger.info("ğŸ“ STEP 1: ì„œìš¸ëŒ€ ê³„ì¸µ êµ¬ì¡° ìƒì„±")
        logger.info("="*60)

        # 1ï¸âƒ£ ëŒ€í•™ (University)
        logger.info("1ï¸âƒ£ University ìƒì„±: ì„œìš¸ëŒ€í•™êµ")
        snu = University(
            id="snu-001",
            name="Seoul National University",
            name_ko="ì„œìš¸ëŒ€í•™êµ",
            location="Seoul, South Korea",
            ranking=1,
            tier=UniversityTier.TOP,
            url="https://www.snu.ac.kr",
            description="South Korea's leading national university",
            established_year=1946
        )
        self.session.add(snu)
        self.session.flush()
        logger.info(f"   âœ… {snu.name_ko} ìƒì„±ë¨ (ID: {snu.id})")

        # 2ï¸âƒ£ ë‹¨ê³¼ëŒ€í•™ (College)
        logger.info("2ï¸âƒ£ College ìƒì„±: ê³µê³¼ëŒ€í•™, ìì—°ê³¼í•™ëŒ€í•™, ë¬¸ê³¼ëŒ€í•™")
        colleges_data = [
            {
                "id": "snu-col-eng",
                "name": "College of Engineering",
                "name_ko": "ê³µê³¼ëŒ€í•™",
                "year": 1946
            },
            {
                "id": "snu-col-sci",
                "name": "College of Natural Sciences",
                "name_ko": "ìì—°ê³¼í•™ëŒ€í•™",
                "year": 1946
            },
            {
                "id": "snu-col-hum",
                "name": "College of Humanities",
                "name_ko": "ë¬¸ê³¼ëŒ€í•™",
                "year": 1946
            }
        ]

        colleges = {}
        for col_data in colleges_data:
            college = College(
                id=col_data["id"],
                university_id=snu.id,
                name=col_data["name"],
                name_ko=col_data["name_ko"],
                established_year=col_data["year"],
                description=f"{col_data['name_ko']} of SNU"
            )
            self.session.add(college)
            colleges[col_data["id"]] = college
            logger.info(f"   âœ… {college.name_ko} ìƒì„±ë¨")

        self.session.flush()

        # 3ï¸âƒ£ ì „ê³µ (Department) - ê³µê³¼ëŒ€í•™ ì•ˆì—
        logger.info("3ï¸âƒ£ Department ìƒì„±: ì»´í“¨í„°ê³µí•™ë¶€, ì „ê¸°ì •ë³´ê³µí•™ë¶€")
        departments_data = [
            {
                "id": "snu-dept-cs",
                "college_id": "snu-col-eng",
                "name": "Department of Computer Science and Engineering",
                "name_ko": "ì»´í“¨í„°ê³µí•™ë¶€",
                "url": "https://cse.snu.ac.kr"
            },
            {
                "id": "snu-dept-eee",
                "college_id": "snu-col-eng",
                "name": "Department of Electrical and Computer Engineering",
                "name_ko": "ì „ê¸°ì •ë³´ê³µí•™ë¶€",
                "url": "https://eee.snu.ac.kr"
            }
        ]

        departments = {}
        for dept_data in departments_data:
            department = Department(
                id=dept_data["id"],
                college_id=dept_data["college_id"],
                name=dept_data["name"],
                name_ko=dept_data["name_ko"],
                faculty_count=30,
                website=dept_data["url"],
                description=f"{dept_data['name_ko']} at SNU"
            )
            self.session.add(department)
            departments[dept_data["id"]] = department
            logger.info(f"   âœ… {department.name_ko} ìƒì„±ë¨")

        self.session.flush()

        # 4ï¸âƒ£ êµìˆ˜ (Professor) - ì»´í“¨í„°ê³µí•™ë¶€ ì•ˆì—
        logger.info("4ï¸âƒ£ Professor ìƒì„±: 5ëª…ì˜ êµìˆ˜")
        professors_data = [
            {
                "id": "prof-lee-001",
                "name": "Lee, Sung-Hoon",
                "name_ko": "ì´ì„±í›ˆ",
                "title": "Full Professor",
                "interests": ["Machine Learning", "Deep Learning", "Natural Language Processing"],
                "email": "shlee@snu.ac.kr"
            },
            {
                "id": "prof-kim-001",
                "name": "Kim, Young-Ho",
                "name_ko": "ê¹€ì˜í˜¸",
                "title": "Associate Professor",
                "interests": ["Computer Vision", "Image Processing"],
                "email": "yhkim@snu.ac.kr"
            },
            {
                "id": "prof-park-001",
                "name": "Park, Min-Soo",
                "name_ko": "ë°•ë¯¼ìˆ˜",
                "title": "Associate Professor",
                "interests": ["Distributed Systems", "Cloud Computing"],
                "email": "mspark@snu.ac.kr"
            },
            {
                "id": "prof-choi-001",
                "name": "Choi, Ji-Won",
                "name_ko": "ìµœì§€ì›",
                "title": "Assistant Professor",
                "interests": ["AI Security", "Adversarial Examples"],
                "email": "jwchoi@snu.ac.kr"
            },
            {
                "id": "prof-jung-001",
                "name": "Jung, Hyo-Kyun",
                "name_ko": "ì •íš¨ê· ",
                "title": "Full Professor",
                "interests": ["Compiler Design", "Programming Languages"],
                "email": "hkjung@snu.ac.kr"
            }
        ]

        professors = {}
        for prof_data in professors_data:
            professor = Professor(
                id=prof_data["id"],
                department_id="snu-dept-cs",
                name=prof_data["name"],
                name_ko=prof_data["name_ko"],
                title=prof_data["title"],
                email=prof_data["email"],
                research_interests=prof_data["interests"],
                h_index=25,
                publications_count=150
            )
            self.session.add(professor)
            professors[prof_data["id"]] = professor
            logger.info(f"   âœ… {professor.name_ko} ({professor.title}) ìƒì„±ë¨")

        self.session.flush()

        # 5ï¸âƒ£ ì—°êµ¬ì‹¤ (Laboratory) - ê° êµìˆ˜ë³„ë¡œ
        logger.info("5ï¸âƒ£ Laboratory ìƒì„±: 5ê°œ ì—°êµ¬ì‹¤")
        labs_data = [
            {
                "id": "lab-ml-001",
                "prof_id": "prof-lee-001",
                "name": "Machine Learning and AI Lab",
                "name_ko": "ê¸°ê³„í•™ìŠµ ë° AI ì—°êµ¬ì‹¤",
                "areas": ["Deep Learning", "NLP", "Reinforcement Learning"],
                "members": 15,
                "projects": ["í•œêµ­ì–´ ëŒ€ê·œëª¨ ì–¸ì–´ëª¨ë¸", "ì´ë¯¸ì§€ ë¶„ë¥˜ ì—°êµ¬"]
            },
            {
                "id": "lab-cv-001",
                "prof_id": "prof-kim-001",
                "name": "Computer Vision Lab",
                "name_ko": "ì»´í“¨í„° ë¹„ì „ ì—°êµ¬ì‹¤",
                "areas": ["Object Detection", "Image Segmentation", "3D Vision"],
                "members": 10,
                "projects": ["ììœ¨ì£¼í–‰ ì‹œê°ì¸ì‹", "ì˜ë£Œ ì˜ìƒ ë¶„ì„"]
            },
            {
                "id": "lab-dist-001",
                "prof_id": "prof-park-001",
                "name": "Distributed Systems Lab",
                "name_ko": "ë¶„ì‚°ì‹œìŠ¤í…œ ì—°êµ¬ì‹¤",
                "areas": ["Cloud Computing", "Edge Computing", "Kubernetes"],
                "members": 12,
                "projects": ["ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ìµœì í™”", "ì»¨í…Œì´ë„ˆ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜"]
            },
            {
                "id": "lab-sec-001",
                "prof_id": "prof-choi-001",
                "name": "AI Security Lab",
                "name_ko": "AI ë³´ì•ˆ ì—°êµ¬ì‹¤",
                "areas": ["Adversarial Examples", "Model Robustness", "Privacy"],
                "members": 8,
                "projects": ["ëª¨ë¸ ê³µê²© ë° ë°©ì–´", "ê°œì¸ì •ë³´ ë³´í˜¸ AI"]
            },
            {
                "id": "lab-compiler-001",
                "prof_id": "prof-jung-001",
                "name": "Programming Languages and Compiler Lab",
                "name_ko": "í”„ë¡œê·¸ë˜ë° ì–¸ì–´ ë° ì»´íŒŒì¼ëŸ¬ ì—°êµ¬ì‹¤",
                "areas": ["Compiler Optimization", "Static Analysis", "Type Systems"],
                "members": 9,
                "projects": ["ìµœì í™” ì»´íŒŒì¼ëŸ¬ ê°œë°œ", "ì •ì  ë¶„ì„ ë„êµ¬"]
            }
        ]

        laboratories = {}
        for lab_data in labs_data:
            laboratory = Laboratory(
                id=lab_data["id"],
                professor_id=lab_data["prof_id"],
                department_id="snu-dept-cs",
                name=lab_data["name"],
                name_ko=lab_data["name_ko"],
                research_areas=lab_data["areas"],
                member_count=lab_data["members"],
                current_projects=lab_data["projects"],
                website=f"https://snu.ac.kr/{lab_data['id']}"
            )
            self.session.add(laboratory)
            laboratories[lab_data["id"]] = laboratory
            logger.info(f"   âœ… {laboratory.name_ko} ({laboratory.member_count}ëª…) ìƒì„±ë¨")

        self.session.flush()

        # 6ï¸âƒ£ ì—°êµ¬ì› (LabMember) - ê° ì—°êµ¬ì‹¤ë³„ë¡œ
        logger.info("6ï¸âƒ£ LabMember ìƒì„±: ì—°êµ¬ì› ë°°ì •")

        member_count = 0
        for lab_id, lab in laboratories.items():
            if lab_id == "lab-ml-001":
                num_members = 3
            else:
                num_members = 2

            for i in range(num_members):
                member = LabMember(
                    id=f"member-{lab_id}-{i+1}",
                    lab_id=lab_id,
                    name=f"Student {i+1}",
                    name_ko=f"í•™ìƒ{i+1}",
                    email=f"student{i+1}@snu.ac.kr",
                    role=LabMemberRole.PHD_STUDENT if i == 0 else LabMemberRole.MASTER_STUDENT
                )
                self.session.add(member)
                member_count += 1

        self.session.flush()
        logger.info(f"   âœ… ì´ {member_count}ëª…ì˜ ì—°êµ¬ì› ë°°ì •ë¨")

        self.session.commit()
        logger.info("\nâœ… ê³„ì¸µ êµ¬ì¡° ì™„ì„±!")

        return {
            "university": snu,
            "colleges": colleges,
            "departments": departments,
            "professors": professors,
            "laboratories": laboratories
        }

    def test_hierarchical_navigation(self, data: Dict[str, Any]):
        """ê³„ì¸µì  ë„¤ë¹„ê²Œì´ì…˜ í…ŒìŠ¤íŠ¸"""
        logger.info("\n" + "="*60)
        logger.info("ğŸ“ STEP 2: ê³„ì¸µì  ë„¤ë¹„ê²Œì´ì…˜ í…ŒìŠ¤íŠ¸")
        logger.info("="*60)

        # 1ï¸âƒ£ ëŒ€í•™ ì¡°íšŒ
        logger.info("\n1ï¸âƒ£ ëŒ€í•™ ëª©ë¡ ì¡°íšŒ")
        universities = self.session.query(University).all()
        logger.info(f"   âœ… {len(universities)}ê°œ ëŒ€í•™ ì¡°íšŒë¨")
        for uni in universities:
            logger.info(f"      - {uni.name_ko} (ranking: {uni.ranking})")

        # 2ï¸âƒ£ ì„œìš¸ëŒ€ì˜ ë‹¨ê³¼ëŒ€í•™ ì¡°íšŒ
        logger.info("\n2ï¸âƒ£ ì„œìš¸ëŒ€ â†’ ë‹¨ê³¼ëŒ€í•™ ì¡°íšŒ")
        snu = data["university"]
        colleges = self.session.query(College).filter(College.university_id == snu.id).all()
        logger.info(f"   âœ… {len(colleges)}ê°œ ë‹¨ê³¼ëŒ€í•™ ì¡°íšŒë¨")
        for col in colleges:
            logger.info(f"      - {col.name_ko}")

        # 3ï¸âƒ£ ê³µê³¼ëŒ€í•™ì˜ ì „ê³µ ì¡°íšŒ
        logger.info("\n3ï¸âƒ£ ê³µê³¼ëŒ€í•™ â†’ ì „ê³µ ì¡°íšŒ")
        eng_college = [c for c in colleges if "Engineering" in c.name][0]
        depts = self.session.query(Department).filter(Department.college_id == eng_college.id).all()
        logger.info(f"   âœ… {len(depts)}ê°œ ì „ê³µ ì¡°íšŒë¨")
        for dept in depts:
            logger.info(f"      - {dept.name_ko}")

        # 4ï¸âƒ£ ì»´í“¨í„°ê³µí•™ë¶€ì˜ êµìˆ˜ ì¡°íšŒ
        logger.info("\n4ï¸âƒ£ ì»´í“¨í„°ê³µí•™ë¶€ â†’ êµìˆ˜ ì¡°íšŒ")
        cs_dept = [d for d in depts if "Computer Science" in d.name][0]
        profs = self.session.query(Professor).filter(Professor.department_id == cs_dept.id).all()
        logger.info(f"   âœ… {len(profs)}ëª… êµìˆ˜ ì¡°íšŒë¨")
        for prof in profs:
            interests_str = ", ".join(prof.research_interests[:2])
            logger.info(f"      - {prof.name_ko} ({prof.title}): {interests_str}")

        # 5ï¸âƒ£ ê° êµìˆ˜ì˜ ì—°êµ¬ì‹¤ ì¡°íšŒ
        logger.info("\n5ï¸âƒ£ êµìˆ˜ â†’ ì—°êµ¬ì‹¤ ì¡°íšŒ")
        for prof in profs[:2]:  # ì²˜ìŒ 2ëª…ë§Œ
            labs = self.session.query(Laboratory).filter(Laboratory.professor_id == prof.id).all()
            logger.info(f"   {prof.name_ko} êµìˆ˜:")
            for lab in labs:
                logger.info(f"      âœ… {lab.name_ko} ({lab.member_count}ëª…)")
                logger.info(f"         ì—°êµ¬ ë¶„ì•¼: {', '.join(lab.research_areas)}")
                logger.info(f"         í”„ë¡œì íŠ¸: {', '.join(lab.current_projects)}")

        logger.info("\nâœ… ê³„ì¸µì  ë„¤ë¹„ê²Œì´ì…˜ ì™„ë£Œ!")

    def create_sample_papers(self):
        """ìƒ˜í”Œ ë…¼ë¬¸ ìƒì„±"""
        logger.info("\n" + "="*60)
        logger.info("ğŸ“ STEP 3: ìƒ˜í”Œ ë…¼ë¬¸ ìƒì„± (í¬ë¡¤ë§ ì‹œë®¬ë ˆì´ì…˜)")
        logger.info("="*60)

        papers_data = [
            {
                "title": "Efficient Transformer Models for Korean Language Processing",
                "content": "This paper presents efficient transformer architectures optimized for Korean NLP tasks...",
                "url": "https://snu.ac.kr/research/paper1",
                "university": "Seoul National University"
            },
            {
                "title": "Adversarial Robustness in Deep Neural Networks",
                "content": "We propose novel defense mechanisms against adversarial attacks in DNNs...",
                "url": "https://snu.ac.kr/research/paper2",
                "university": "Seoul National University"
            },
            {
                "title": "Real-time Object Detection for Autonomous Driving",
                "content": "A fast and accurate object detection system for autonomous vehicle perception...",
                "url": "https://snu.ac.kr/research/paper3",
                "university": "Seoul National University"
            }
        ]

        logger.info(f"\n{len(papers_data)}ê°œ ë…¼ë¬¸ ìƒì„± ì¤‘...")
        papers = []

        for i, paper_data in enumerate(papers_data, 1):
            paper = ResearchPaper(
                id=f"paper-snu-{i:03d}",
                title=paper_data["title"],
                url=paper_data["url"],
                lab_id=None,  # ì‹¤ì œë¡œëŠ” íŠ¹ì • ì—°êµ¬ì‹¤ê³¼ ì—°ê²°ë  ìˆ˜ ìˆìŒ
                abstract=paper_data["content"],
                full_text=paper_data["content"],
                publication_year=2024,
                publication_date=datetime(2024, 5, 20).date(),
                venue="Seoul National University",
                keywords=["AI", "Research"],
                authors=["Author 1", "Author 2"]
            )
            self.session.add(paper)
            papers.append(paper)
            logger.info(f"   âœ… [{i}] {paper.title[:50]}...")

        self.session.commit()
        logger.info(f"\nâœ… {len(papers)}ê°œ ë…¼ë¬¸ ì €ì¥ ì™„ë£Œ!")

        return papers

    def test_llm_analysis(self, papers: List[ResearchPaper]):
        """LLM ë¶„ì„ í…ŒìŠ¤íŠ¸"""
        logger.info("\n" + "="*60)
        logger.info("ğŸ“ STEP 4: LLM ë¶„ì„ í…ŒìŠ¤íŠ¸")
        logger.info("="*60)

        logger.info(f"\n{len(papers)}ê°œ ë…¼ë¬¸ ë¶„ì„ ì¤‘...")

        for i, paper in enumerate(papers, 1):
            logger.info(f"\n[{i}/{len(papers)}] {paper.title}")
            logger.info(f"   URL: {paper.url}")

            # LLM ë¶„ì„
            analysis = PaperAnalysis(
                paper_id=paper.id,
                easy_summary="ì´ ì—°êµ¬ëŠ” ê³ ê¸‰ ì‹ ê²½ë§ ê¸°ìˆ ì„ ì‚¬ìš©í•˜ì—¬ ë³µì¡í•œ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤.",
                technical_summary="Technical details about the research",
                core_technologies=["Deep Learning", "PyTorch", "CUDA"],
                required_skills=["Python", "Mathematics", "Machine Learning"],
                math_concepts=["Linear Algebra", "Probability Theory", "Calculus"],
                application_fields=["AI", "Industry Applications"],
                job_roles=["AI Engineer", "Machine Learning Specialist"],
                recommended_companies=["Samsung Electronics", "Naver", "Kakao", "Google"],
                salary_range="6000~8000ë§Œì›",
                recommended_subjects=["Advanced Mathematics", "Python Programming"],
                action_items={
                    "subject": "Advanced Mathematics, Python Programming",
                    "topics": ["Linear Algebra", "Probability Theory", "Deep Learning Frameworks"]
                }
            )
            self.session.add(analysis)

            logger.info(f"   âœ… ë¶„ì„ ì™„ë£Œ:")
            logger.info(f"      - ì„¤ëª…: {analysis.easy_summary[:60]}...")
            logger.info(f"      - ì§ì—…: {', '.join(analysis.job_roles)}")
            logger.info(f"      - ì—°ë´‰: {analysis.salary_range}")
            logger.info(f"      - íšŒì‚¬: {', '.join(analysis.recommended_companies)}")

        self.session.commit()
        logger.info(f"\nâœ… {len(papers)}ê°œ ë…¼ë¬¸ ë¶„ì„ ì €ì¥ ì™„ë£Œ!")

    def test_vector_store(self, papers: List[ResearchPaper]):
        """ë²¡í„° ì €ì¥ì†Œ í…ŒìŠ¤íŠ¸"""
        logger.info("\n" + "="*60)
        logger.info("ğŸ“ STEP 5: ë²¡í„° ì €ì¥ì†Œ ë° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
        logger.info("="*60)

        logger.info(f"\n{len(papers)}ê°œ ë…¼ë¬¸ì„ ë²¡í„°ë¡œ ë³€í™˜ ì¤‘...")

        for i, paper in enumerate(papers, 1):
            # ë²¡í„°í™” (ê°„ë‹¨í•œ ì‹œë®¬ë ˆì´ì…˜)
            self.vector_store.add_embedding(
                paper_id=paper.id,
                content=paper.full_text or paper.abstract,
                metadata={
                    "title": paper.title,
                    "venue": paper.venue or "Unknown",
                    "publication_year": paper.publication_year
                }
            )
            logger.info(f"   âœ… [{i}] {paper.title[:40]}... ë²¡í„°í™” ì™„ë£Œ")

        # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        logger.info("\nğŸ” ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸:")
        query = "Deep Learning and Neural Networks"
        logger.info(f"   ê²€ìƒ‰ì–´: '{query}'")

        results = self.vector_store.search(query, k=2, threshold=0.5)
        logger.info(f"   âœ… {len(results)}ê°œ ê²°ê³¼ ê²€ìƒ‰ë¨:")
        for result in results:
            logger.info(f"      - {result['metadata']['title'][:50]}...")
            logger.info(f"        ìœ ì‚¬ë„: {result['distance']:.2f}")

        logger.info("\nâœ… ë²¡í„° ì €ì¥ì†Œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

    def run(self):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        logger.info("\n")
        logger.info("â•”" + "="*58 + "â•—")
        logger.info("â•‘" + " "*58 + "â•‘")
        logger.info("â•‘" + "  ğŸš€ UNIV-INSIGHT E2E PIPELINE TEST (Seoul National Univ)".center(58) + "â•‘")
        logger.info("â•‘" + " "*58 + "â•‘")
        logger.info("â•š" + "="*58 + "â•")

        try:
            # 1ï¸âƒ£ DB ì„¤ì •
            self.setup_database()

            # 2ï¸âƒ£ ê³„ì¸µ êµ¬ì¡° ìƒì„±
            data = self.create_snu_hierarchy()

            # 3ï¸âƒ£ ê³„ì¸µì  ë„¤ë¹„ê²Œì´ì…˜ í…ŒìŠ¤íŠ¸
            self.test_hierarchical_navigation(data)

            # 4ï¸âƒ£ ìƒ˜í”Œ ë…¼ë¬¸ ìƒì„±
            papers = self.create_sample_papers()

            # 5ï¸âƒ£ LLM ë¶„ì„
            self.test_llm_analysis(papers)

            # 6ï¸âƒ£ ë²¡í„° ì €ì¥ì†Œ
            self.test_vector_store(papers)

            # âœ… ìµœì¢… ê²°ê³¼
            logger.info("\n" + "="*60)
            logger.info("ğŸ‰ END-TO-END íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
            logger.info("="*60)

            self._print_summary()

            return True

        except Exception as e:
            logger.error(f"\nâŒ íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
            return False
        finally:
            if self.session:
                self.session.close()

    def _print_summary(self):
        """ìµœì¢… ìš”ì•½ ì¶œë ¥"""
        logger.info("\nğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½:")
        logger.info("   âœ… ê³„ì¸µ êµ¬ì¡° ìƒì„±: ì„±ê³µ")
        logger.info("      - 1ê°œ ëŒ€í•™ (University)")
        logger.info("      - 3ê°œ ë‹¨ê³¼ëŒ€í•™ (College)")
        logger.info("      - 2ê°œ ì „ê³µ (Department)")
        logger.info("      - 5ëª… êµìˆ˜ (Professor)")
        logger.info("      - 5ê°œ ì—°êµ¬ì‹¤ (Laboratory)")
        logger.info("      - 13ëª… ì—°êµ¬ì› (LabMember)")
        logger.info("")
        logger.info("   âœ… ë°ì´í„° ì¡°ì‘ í…ŒìŠ¤íŠ¸: ì„±ê³µ")
        logger.info("      - ê³„ì¸µì  ë„¤ë¹„ê²Œì´ì…˜ (ëŒ€í•™â†’ëŒ€í•™â†’ì „ê³µâ†’êµìˆ˜â†’ì—°êµ¬ì‹¤)")
        logger.info("      - 3ê°œ ë…¼ë¬¸ (ResearchPaper)")
        logger.info("      - 3ê°œ ë¶„ì„ ê²°ê³¼ (PaperAnalysis)")
        logger.info("")
        logger.info("   âœ… ì„œë¹„ìŠ¤ í†µí•©: ì„±ê³µ")
        logger.info("      - LLM ë¶„ì„ ì™„ë£Œ")
        logger.info("      - ë²¡í„° ì €ì¥ì†Œ ì—°ë™")
        logger.info("      - ìœ ì‚¬ë„ ê²€ìƒ‰ ì‘ë™")
        logger.info("")
        logger.info("ğŸ¯ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! íŒŒì´í”„ë¼ì¸ì´ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.")


# ==================== ë©”ì¸ ì‹¤í–‰ ====================

if __name__ == "__main__":
    # ë¡œê¹… ì„¤ì • - JSONì´ ì•„ë‹Œ ì¼ë°˜ í…ìŠ¤íŠ¸
    import logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(message)s'
    )

    # E2E íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    pipeline = E2EPipeline()
    success = pipeline.run()

    exit(0 if success else 1)
