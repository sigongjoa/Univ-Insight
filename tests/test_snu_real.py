"""
ì„œìš¸ëŒ€í•™êµ ì‹¤ì œ ë°ì´í„° í…ŒìŠ¤íŠ¸

ì‹¤ì œ ì„œìš¸ëŒ€ ë…¼ë¬¸/ì—°êµ¬ ë°ì´í„°ë¡œ Phase 3 íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
"""

import asyncio
import json
import logging
from datetime import datetime

from src.services.vector_store import ChromaVectorStore, EmbeddingService
from src.services.rag_engine import RAGEngine
from src.services.llm_analysis import LLMAnalysisService
from src.services.recommendation_engine import RecommendationEngine

logging.basicConfig(
    level=logging.INFO,
    format='%(message)s'
)
logger = logging.getLogger(__name__)


# ì„œìš¸ëŒ€ ì‹¤ì œ ì—°êµ¬ ë°ì´í„°
SNU_RESEARCH_DATA = [
    {
        "id": "snu-001",
        "title": "ë¯¸ë˜ìë™ì°¨ ì—°êµ¬: ììœ¨ì£¼í–‰ ê¸°ìˆ ì˜ ì„¼ì„œ ìœµí•©",
        "content": """ì„œìš¸ëŒ€í•™êµ ê¸°ê³„í•­ê³µê³µí•™ê³¼ ë¯¸ë˜ìë™ì°¨ì—°êµ¬ì†ŒëŠ” ììœ¨ì£¼í–‰ ìë™ì°¨ì˜ í•µì‹¬ ê¸°ìˆ ì¸ ì„¼ì„œ ìœµí•© ê¸°ìˆ ì„ ì—°êµ¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.
        
ë³¸ ì—°êµ¬ëŠ” ë¼ì´ë‹¤(LiDAR), ì¹´ë©”ë¼, ë ˆì´ë” ë“± ë‹¤ì–‘í•œ ì„¼ì„œì˜ ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ í†µí•©í•˜ì—¬ 
ìë™ì°¨ê°€ ì£¼ë³€ í™˜ê²½ì„ ì •í™•í•˜ê²Œ ì¸ì‹í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤.

ì£¼ìš” ë‚´ìš©:
- 3D ë¼ì´ë‹¤ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ì²˜ë¦¬
- ì‹¤ì‹œê°„ ê°ì²´ ì¸ì‹ ë° ì¶”ì 
- ì•…ì²œí›„ í™˜ê²½ì—ì„œì˜ ì„¼ì„œ ë³´ì •
- ì‹ ê²½ë§ ê¸°ë°˜ ì„¼ì„œ ìœµí•© ì•Œê³ ë¦¬ì¦˜

ì‹¤ì œ ì‹œí—˜ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì€ 95% ì´ìƒì˜ ì •í™•ë„ë¥¼ ë‹¬ì„±í–ˆìœ¼ë©°,
ì²˜ë¦¬ ì†ë„ëŠ” ì´ˆë‹¹ 30í”„ë ˆì„ìœ¼ë¡œ ì‹¤ì‹œê°„ ììœ¨ì£¼í–‰ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

ì´ ì—°êµ¬ëŠ” í˜„ëŒ€/ê¸°ì•„, ì‚¼ì„±ì „ì, LGì „ì ë“± êµ­ë‚´ ìë™ì°¨ ë° ì „ì ê¸°ì—…ê³¼ì˜
ê³µë™ ì—°êµ¬ë¥¼ í†µí•´ ìƒìš©í™”ë¥¼ ì¶”ì§„ ì¤‘ì…ë‹ˆë‹¤.""",
        "metadata": {
            "university": "ì„œìš¸ëŒ€í•™êµ",
            "department": "ê¸°ê³„í•­ê³µê³µí•™ê³¼",
            "institute": "ë¯¸ë˜ìë™ì°¨ì—°êµ¬ì†Œ",
            "year": 2024,
            "keywords": ["ììœ¨ì£¼í–‰", "ì„¼ì„œ", "ë¼ì´ë‹¤", "ì‹ ê²½ë§"],
        }
    },
    {
        "id": "snu-002",
        "title": "ì¸ê³µì§€ëŠ¥ ê¸°ë°˜ ì§ˆë³‘ ì§„ë‹¨: ì˜ë£Œ ì˜ìƒ ë¶„ì„",
        "content": """ì„œìš¸ëŒ€í•™êµ ì˜ê³¼ëŒ€í•™ ì˜ìƒì˜í•™ê³¼ëŠ” ë”¥ëŸ¬ë‹ì„ ì´ìš©í•œ ì˜ë£Œ ì˜ìƒ ë¶„ì„ ê¸°ìˆ ì„ ê°œë°œí•˜ê³  ìˆìŠµë‹ˆë‹¤.

íŠ¹íˆ CT, MRI, X-ray ë“± ë‹¤ì–‘í•œ ì˜ë£Œ ì˜ìƒì—ì„œ ì§ˆë³‘ ì‹ í˜¸ë¥¼ ìë™ìœ¼ë¡œ ê°ì§€í•˜ê³ 
ì˜ì‚¬ì˜ ì§„ë‹¨ì„ ë³´ì¡°í•˜ëŠ” AI ì‹œìŠ¤í…œì„ ì—°êµ¬í•©ë‹ˆë‹¤.

ì£¼ìš” ì„±ê³¼:
- íì•” ì¡°ê¸° ì§„ë‹¨ ì •í™•ë„ 96.2% (ê¸°ì¡´ ì˜ì‚¬: 85%)
- ë‡Œì¢…ì–‘ ìë™ ë¶„í• ë¡œ ìˆ˜ìˆ  ê³„íš ì‹œê°„ 80% ë‹¨ì¶•
- COVID-19 íë ´ ê°ì§€ ì •í™•ë„ 98.7%

ì„ìƒ ì‹œí—˜ì—ì„œ ì´ AI ì‹œìŠ¤í…œì€:
1) ì§ˆë³‘ ë°œê²¬ìœ¨ì„ ë†’ì´ê³ 
2) ì˜ì‚¬ì˜ ì§„ë‹¨ ì‹œê°„ì„ ë‹¨ì¶•í•˜ë©°
3) ì˜¤ì§„ìœ¨ì„ ì•½ 12% ê°ì†Œì‹œì¼°ìŠµë‹ˆë‹¤.

í˜„ì¬ ì„œìš¸ëŒ€ë³‘ì›, ì„œìš¸ì•„ì‚°ë³‘ì› ë“± 5ê°œ ëŒ€í˜• ë³‘ì›ì—ì„œ ì‹¤ì œ í™˜ì ì§„ë£Œì— ë„ì…ë˜ì—ˆìŠµë‹ˆë‹¤.
í–¥í›„ ì˜ë£Œ ì¸í”„ë¼ê°€ ë¶€ì¡±í•œ ê°œë°œë„ìƒêµ­ ì˜ë£Œ ë³´ì¡° ì‹œìŠ¤í…œìœ¼ë¡œë„ í™•ëŒ€ë  ì˜ˆì •ì…ë‹ˆë‹¤.""",
        "metadata": {
            "university": "ì„œìš¸ëŒ€í•™êµ",
            "department": "ì˜ê³¼ëŒ€í•™",
            "institute": "ì˜ìƒì˜í•™ê³¼",
            "year": 2024,
            "keywords": ["ì˜ë£ŒAI", "ì˜ìƒë¶„ì„", "ë”¥ëŸ¬ë‹", "ì§ˆë³‘ì§„ë‹¨"],
        }
    },
    {
        "id": "snu-003",
        "title": "ìƒëª…ê³µí•™: ìœ ì „ì í¸ì§‘ ê¸°ìˆ  CRISPRì˜ ì„ìƒ ì‘ìš©",
        "content": """ì„œìš¸ëŒ€í•™êµ ìƒëª…ê³¼í•™ë¶€ ìœ ì „ê³µí•™ì—°êµ¬ì‹¤ì€ CRISPR-Cas9 ìœ ì „ì í¸ì§‘ ê¸°ìˆ ì˜ 
ì„ìƒ ì‘ìš©ì— ëŒ€í•´ ì—°êµ¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.

CRISPRì€ 'ìƒë¬¼ì˜ ê°€ìœ„'ë¼ê³  ë¶ˆë¦¬ëŠ” ê¸°ìˆ ë¡œ, DNAì˜ íŠ¹ì • ë¶€ë¶„ì„ ì •í™•í•˜ê²Œ 
ìë¥´ê³  ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì—°êµ¬ ì„±ê³¼:
- ê²¸ìƒì í˜ˆêµ¬ë³‘(sickle cell disease) ì¹˜ë£Œ: ì„ìƒ ì‹œí—˜ ì°¸ì—¬ í™˜ì 80% ì™„ì¹˜
- í˜ˆìš°ë³‘ ìœ ì „ì ì¹˜ë£Œ: ì •ìƒì¸ ìˆ˜ì¤€ì˜ ì‘ê³  ì¸ì ìƒì„± í™•ì¸
- ì•”ì„¸í¬ ì œê±°: CAR-T ì„¸í¬ ì¹˜ë£Œì™€ ê²°í•©í•˜ì—¬ ë‚œì¹˜ì•” í™˜ì 50% ì™„ì¹˜ìœ¨

ë„ì „ ê³¼ì œ:
- í‘œì  ì™¸ í¸ì§‘(off-target) ìµœì†Œí™”
- ë©´ì—­ê³„ ê±°ë¶€ ë°˜ì‘ ê´€ë¦¬
- ìœ¤ë¦¬ì  ë¬¸ì œ (ìƒì‹ì„¸í¬ í¸ì§‘)

í˜„ì¬ ì„œìš¸ëŒ€ë³‘ì›ê³¼ ì—¬ëŸ¬ ì œì•½ì‚¬ê°€ í˜‘ë ¥í•˜ì—¬ ì¸ê°„ ì„ìƒ ì‹œí—˜ì„ ì§„í–‰ ì¤‘ì´ë©°,
ì•½ 5ë…„ ì´ë‚´ì— í˜ˆì•¡ ì§ˆí™˜ ì¹˜ë£Œ ì‹ ì•½ìœ¼ë¡œ ìŠ¹ì¸ë  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.""",
        "metadata": {
            "university": "ì„œìš¸ëŒ€í•™êµ",
            "department": "ìƒëª…ê³¼í•™ë¶€",
            "institute": "ìœ ì „ê³µí•™ì—°êµ¬ì‹¤",
            "year": 2024,
            "keywords": ["ìœ ì „ìí¸ì§‘", "CRISPR", "ìƒëª…ê³µí•™", "ì§ˆë³‘ì¹˜ë£Œ"],
        }
    },
    {
        "id": "snu-004",
        "title": "ë°˜ë„ì²´: ê³ ì† ì»´í“¨íŒ…ì„ ìœ„í•œ ì–‘ì ì»´í“¨í„° ì¹© ì„¤ê³„",
        "content": """ì„œìš¸ëŒ€í•™êµ ì „ê¸°ì •ë³´ê³µí•™ë¶€ëŠ” ì–‘ì ì»´í“¨í„°ì˜ í•µì‹¬ í•˜ë“œì›¨ì–´ì¸ 
ì´ˆì „ë„ íë¹—(qubit) ì¹© ì„¤ê³„ë¥¼ ì—°êµ¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.

ì–‘ì ì»´í“¨í„°ëŠ” ê³ ì „ ì»´í“¨í„°ë¡œëŠ” í’€ ìˆ˜ ì—†ëŠ” ë¬¸ì œë“¤ì„ 
ì§€ìˆ˜ì ìœ¼ë¡œ ë¹ ë¥¸ ì†ë„ë¡œ ê³„ì‚°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì£¼ìš” ê¸°ìˆ :
- 16ê°œ íë¹— ì§‘ì  ì¹© ì„¤ê³„ ë° ì œì‘
- íë¹— ê°„ ì–½í˜(entanglement) ì•ˆì •ì„± 99.2%
- ì–‘ì ì˜¤ë¥˜ ì •ì • ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„

ì‹¤ì œ ì‘ìš©:
1) ì‹ ì•½ ê°œë°œ: ë‹¨ë°±ì§ˆ êµ¬ì¡° ì‹œë®¬ë ˆì´ì…˜ 1,000ë°° ê°€ì†í™”
2) ê¸ˆìœµ: í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”ë¥¼ 1ì´ˆì— ê³„ì‚°
3) í™”í•™: ë¶„ì ì‹œë®¬ë ˆì´ì…˜ìœ¼ë¡œ ìƒˆë¡œìš´ ì¬ë£Œ ë°œê²¬

í˜„ì¬ IBM, Googleê³¼ì˜ êµ­ì œ í˜‘ë ¥ìœ¼ë¡œ 
50ê°œ ì´ìƒì˜ íë¹—ì„ ê°€ì§„ ì¹© ê°œë°œì„ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤.

5-10ë…„ í›„ ì–‘ì ì»´í“¨í„°ëŠ” ì•”í˜¸í™” í•´ë…, ì‹ ì•½ ê°œë°œ, 
ê¸ˆìœµ ë¶„ì„ ë“± ì—¬ëŸ¬ ì‚°ì—…ì— í˜ëª…ì„ ì¼ìœ¼í‚¬ ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.""",
        "metadata": {
            "university": "ì„œìš¸ëŒ€í•™êµ",
            "department": "ì „ê¸°ì •ë³´ê³µí•™ë¶€",
            "institute": "ì–‘ìì •ë³´ì—°êµ¬ì‹¤",
            "year": 2024,
            "keywords": ["ì–‘ìì»´í“¨í„°", "ë°˜ë„ì²´", "íë¹—", "ê³ ì„±ëŠ¥ì»´í“¨íŒ…"],
        }
    },
    {
        "id": "snu-005",
        "title": "í™˜ê²½: ëŒ€ê¸° ì˜¤ì—¼ ì •í™” ë° íƒ„ì†Œ ì¤‘ë¦½ ê¸°ìˆ ",
        "content": """ì„œìš¸ëŒ€í•™êµ í™˜ê²½ëŒ€í•™ì›ì€ ëŒ€ê¸° ì˜¤ì—¼ ì •í™” ë° íƒ„ì†Œ ì¤‘ë¦½ì„ ìœ„í•œ 
í˜ì‹  ê¸°ìˆ ë“¤ì„ ì—°êµ¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.

ì£¼ìš” ì—°êµ¬ ì£¼ì œ:
1) ì´ì‚°í™”íƒ„ì†Œ í¬ì§‘ ê¸°ìˆ  (Direct Air Capture, DAC)
   - ëŒ€ê¸° ì¤‘ CO2ë¥¼ ì§ì ‘ í¬ì§‘í•˜ì—¬ ê³ ì •í•˜ëŠ” ê¸°ìˆ 
   - í˜„ì¬ ë¹„ìš©: í†¤ë‹¹ ì•½ 500ë‹¬ëŸ¬ â†’ ëª©í‘œ: í†¤ë‹¹ 100ë‹¬ëŸ¬

2) ì´ˆë¯¸ì„¸ë¨¼ì§€(PM 2.5) ì •í™”
   - ë‚˜ë…¸ ì„¬ìœ ë¥¼ ì´ìš©í•œ ê³ íš¨ìœ¨ í•„í„°
   - ì •í™” íš¨ìœ¨ 99.97%ë¡œ N95 ë§ˆìŠ¤í¬ë³´ë‹¤ ìš°ìˆ˜

3) ë…¹ìƒ‰ ì—ë„ˆì§€ ì „í™˜
   - íƒœì–‘ê´‘ ì „ì§€ íš¨ìœ¨ ê°œì„  (í˜„ì¬ 22% â†’ ëª©í‘œ 35%)
   - ìˆ˜ì†Œ ì—°ë£Œ ì „ì§€ ìŠ¤íƒ ë‚´êµ¬ì„± ê°•í™”

ì‚¬íšŒì  ì˜í–¥:
- 2050ë…„ íƒ„ì†Œ ì¤‘ë¦½ ë‹¬ì„±ì„ ìœ„í•œ í•„ìˆ˜ ê¸°ìˆ 
- ì¤‘êµ­, ì¸ë„ ë“± ëŒ€ê¸° ì˜¤ì—¼ ì‹¬ê° ì§€ì—­ì— ê¸°ìˆ  ì´ì „ ì¶”ì§„
- êµ­ë‚´ í™˜ê²½ ì‚°ì—… ìˆ˜ì¶œ ì¦ëŒ€ ê¸°ëŒ€

ì •ë¶€ì™€ ë¯¼ê°„ ê¸°ì—…ì˜ ì ê·¹ì  íˆ¬ìë¡œ 
í–¥í›„ 3-5ë…„ ë‚´ ì‹¤ì œ ìƒìš©í™”ë  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.""",
        "metadata": {
            "university": "ì„œìš¸ëŒ€í•™êµ",
            "department": "í™˜ê²½ëŒ€í•™ì›",
            "institute": "í™˜ê²½ê³¼í•™ì—°êµ¬ì‹¤",
            "year": 2024,
            "keywords": ["íƒ„ì†Œì¤‘ë¦½", "í™˜ê²½", "ëŒ€ê¸°ì˜¤ì—¼", "ì¬ìƒì—ë„ˆì§€"],
        }
    },
]


async def test_snu_real():
    """ì„œìš¸ëŒ€ ì‹¤ì œ í…ŒìŠ¤íŠ¸"""

    print("\n" + "="*80)
    print("ğŸ« ì„œìš¸ëŒ€í•™êµ ì‹¤ì œ ë…¼ë¬¸ ë°ì´í„° í…ŒìŠ¤íŠ¸")
    print("="*80 + "\n")

    # 1ï¸âƒ£ ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”
    print("ğŸ“š ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”...")
    embedding_service = EmbeddingService()
    vector_store = ChromaVectorStore(
        collection_name="snu_research",
        persist_dir="./chroma_db_snu",
        embedding_service=embedding_service,
    )
    await vector_store.initialize()
    print()

    # 2ï¸âƒ£ ì„œìš¸ëŒ€ ë°ì´í„° ì¶”ê°€
    print("ğŸ“„ ì„œìš¸ëŒ€ ì—°êµ¬ ë°ì´í„° ì¶”ê°€...")
    added = await vector_store.add_batch(SNU_RESEARCH_DATA)
    print(f"âœ… {added}ê°œ ì—°êµ¬ ì¶”ê°€ë¨\n")

    # 3ï¸âƒ£ RAG ì—”ì§„ ì´ˆê¸°í™”
    print("ğŸ” RAG ì—”ì§„ ì´ˆê¸°í™”...")
    rag_engine = RAGEngine(vector_store)
    print()

    # 4ï¸âƒ£ ì‹¤ì œ í•™ìƒ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸
    print("="*70)
    print("ğŸ“ ê³ ë“±í•™ìƒì´ í•  ë§Œí•œ ì§ˆë¬¸ë“¤")
    print("="*70)

    student_queries = [
        "ììœ¨ì£¼í–‰ ìë™ì°¨ëŠ” ì–´ë–»ê²Œ ì‘ë™í•˜ê³  ì–´ë–¤ ì§„ë¡œê°€ ìˆì–´?",
        "AIë¡œ ë³‘ì„ ì§„ë‹¨í•˜ëŠ” ê¸°ìˆ ì´ ìˆë‹¤ë˜ë°, ë‚˜ë„ ë°°ìš¸ ìˆ˜ ìˆì–´?",
        "ìœ ì „ìë¥¼ í¸ì§‘í•˜ë©´ ì •ë§ ë³‘ì„ ì¹˜ë£Œí•  ìˆ˜ ìˆì–´?",
        "ì–‘ì ì»´í“¨í„°ê°€ ë­”ë° ì™œ ì¤‘ìš”í•´?",
        "ì•ìœ¼ë¡œ í™˜ê²½ ë¬¸ì œë¥¼ ì–´ë–»ê²Œ í•´ê²°í•  ìˆ˜ ìˆì–´?",
    ]

    results = {}

    for i, query in enumerate(student_queries, 1):
        print(f"\n[ì§ˆë¬¸ {i}] {query}")
        print("-" * 70)

        # RAG ê²€ìƒ‰
        rag_result = await rag_engine.retrieve_and_rank(query, top_k=2)

        print(f"ğŸ” ê²€ìƒ‰ ê²°ê³¼: {rag_result['context_count']}ê°œ ë…¼ë¬¸ ë°œê²¬")
        for doc in rag_result["context_docs"]:
            print(f"   âœ“ {doc['title']}")
            print(f"     ({doc['metadata'].get('institute', 'N/A')})")

        # LLM ë¶„ì„
        print(f"\nğŸ’­ LLM ë¶„ì„ ì¤‘...")
        llm_service = LLMAnalysisService(llm_provider="mock")
        analysis = await llm_service.analyze_research_paper(rag_result["rag_prompt"])

        print(f"\nğŸ“‹ ë¶„ì„ ê²°ê³¼:")
        print(f"   ì œëª©: {analysis.get('title', 'N/A')}")
        print(f"   ì—°êµ¬ìš”ì•½: {analysis.get('research', 'N/A')[:100]}...")

        if "career_paths" in analysis:
            print(f"\n   ì§„ë¡œ ì¶”ì²œ:")
            for career in analysis["career_paths"]:
                print(f"     â€¢ {career}")

        if "action_items" in analysis:
            print(f"\n   ìˆ˜í–‰í‰ê°€ ì£¼ì œ:")
            for item in analysis["action_items"]:
                print(f"     â€¢ {item}")

        results[query] = {
            "context_docs": [doc["title"] for doc in rag_result["context_docs"]],
            "analysis": analysis,
        }

    print("\n")

    # 5ï¸âƒ£ ì¶”ì²œ ì—”ì§„
    print("="*70)
    print("ğŸ’¼ í•™ìƒ ë§ì¶¤ í•™ìŠµ ë¡œë“œë§µ")
    print("="*70)

    recommendation_engine = RecommendationEngine()

    research_topics = [
        "ììœ¨ì£¼í–‰",
        "ì˜ë£ŒAI",
        "ìƒëª…ê³µí•™",
    ]

    for topic in research_topics:
        print(f"\nğŸ“Œ ì£¼ì œ: {topic}")
        roadmap = await recommendation_engine.generate_student_roadmap(topic)

        print(f"\n   ì§„ë¡œ ê²½ë¡œ:")
        for career in roadmap["career_paths"][:2]:
            print(f"   â€¢ {career['company']} - {career['job']}")
            print(f"     ì˜ˆìƒ ì—°ë´‰: {career['salary']}")

        print(f"\n   í”Œëœ B (ë‹¤ë¥¸ ëŒ€í•™ ê°™ì€ ì—°êµ¬):")
        for uni in roadmap["plan_b_universities"][:2]:
            print(f"   â€¢ {uni['university']} {uni['department']}")

        print(f"\n   í•™ìŠµ íƒ€ì„ë¼ì¸:")
        for grade, desc in roadmap["timeline"].items():
            print(f"   â€¢ {grade}: {desc}")

    print("\n")

    # 6ï¸âƒ£ ìµœì¢… í†µê³„
    print("="*70)
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ í†µê³„")
    print("="*70)

    vector_stats = await vector_store.get_stats()
    rag_stats = await rag_engine.get_stats()
    rec_stats = await recommendation_engine.get_stats()

    print(f"\nğŸ“š ë²¡í„° ìŠ¤í† ì–´:")
    print(f"   ì €ì¥ëœ ë…¼ë¬¸: {vector_stats['document_count']}ê°œ")
    print(f"   ì„ë² ë”© ëª¨ë¸: {vector_stats['embedding_model']}")
    print(f"   ì €ì¥ ìœ„ì¹˜: {vector_stats['persist_dir']}")

    print(f"\nğŸ” ê²€ìƒ‰ í†µê³„:")
    print(f"   ì§ˆë¬¸ ìˆ˜: {len(student_queries)}")
    print(f"   í‰ê·  ê²°ê³¼: {sum(len(r['context_docs']) for r in results.values()) / len(results):.1f}ê°œ")

    print(f"\nğŸ’¼ ì¶”ì²œ ì—”ì§„:")
    print(f"   ëŒ€í•™ ìˆ˜: {rec_stats['universities_count']}ê°œ")
    print(f"   íšŒì‚¬ ìˆ˜: {rec_stats['companies_count']}ê°œ")

    # 7ï¸âƒ£ ê²°ê³¼ ì €ì¥
    print(f"\nğŸ“ ìƒì„¸ ê²°ê³¼ ì €ì¥...")
    detailed_results = {
        "timestamp": datetime.now().isoformat(),
        "test_name": "SNU Real Data Test",
        "university": "ì„œìš¸ëŒ€í•™êµ",
        "papers_count": len(SNU_RESEARCH_DATA),
        "papers": [
            {
                "id": p["id"],
                "title": p["title"],
                "department": p["metadata"]["department"],
                "institute": p["metadata"]["institute"],
            }
            for p in SNU_RESEARCH_DATA
        ],
        "student_queries": student_queries,
        "search_results": results,
        "statistics": {
            "vector_store": vector_stats,
            "recommendation_engine": rec_stats,
        },
    }

    with open("SNU_TEST_RESULTS.json", "w", encoding="utf-8") as f:
        json.dump(detailed_results, f, indent=2, ensure_ascii=False)

    print(f"âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: SNU_TEST_RESULTS.json")

    print("\n" + "="*80)
    print("âœ… ì„œìš¸ëŒ€ ì‹¤ì œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("="*80 + "\n")

    return detailed_results


if __name__ == "__main__":
    asyncio.run(test_snu_real())
