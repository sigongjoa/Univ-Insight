import asyncio
import sys
import os
import logging

# Add project root to sys.path
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from src.services.deep_crawler import DeepCrawler

logging.basicConfig(level=logging.INFO)

async def main():
    print(">>> [Phase 2-3] Deep Crawler Test")
    
    # í…ŒìŠ¤íŠ¸ ëŒ€ìƒ: KAIST ì „ì‚°í•™ë¶€ (ì´ë¯¸ URL Discoveryë¡œ ì°¾ì€ URL)
    target_url = "https://cs.kaist.ac.kr/people/view?type=faculty" 
    # ì£¼ì˜: ì‹¤ì œ ë¦¬ìŠ¤íŠ¸ í˜ì´ì§€ URLì€ ë©”ì¸ í˜ì´ì§€ì™€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ. 
    # ì¼ë‹¨ ë©”ì¸ í˜ì´ì§€ë‚˜ ì‚¬ëŒ ëª©ë¡ í˜ì´ì§€ë¥¼ íƒ€ê²ŸíŒ…í•´ì•¼ í•¨.
    # KAIST CSì˜ ê²½ìš° /people/view?type=faculty ê°€ êµìˆ˜ì§„ ëª©ë¡ì„.
    # Discoveryê°€ ì°¾ì•„ì¤€ê±´ ë©”ì¸(https://cs.kaist.ac.kr)ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, 
    # ì‹¤ì œë¡œëŠ” "Faculty" ë§í¬ë¥¼ ì°¾ëŠ” ë¡œì§ì´ ì¶”ê°€ë¡œ í•„ìš”í•˜ì§€ë§Œ, 
    # ì—¬ê¸°ì„œëŠ” ë°ëª¨ë¥¼ ìœ„í•´ ì§ì ‘ êµìˆ˜ì§„ í˜ì´ì§€ë¥¼ ì…ë ¥í•´ë´„.
    
    # ë§Œì•½ ë©”ì¸ í˜ì´ì§€ë¼ë©´ LLMì´ "Faculty" ë§í¬ë¥¼ ì°¾ì•„ë‚´ê²Œ í•˜ëŠ”ê²Œ Best.
    # ì¼ë‹¨ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì§ì ‘ URL ì§€ì •.
    
    crawler = DeepCrawler(model_name="llama2:latest") # User env has llama2
    
    print(f"\n>>> Crawling: {target_url}")
    professors = await crawler.extract_professors_from_url(target_url)
    
    print(f"\n>>> Extracted {len(professors)} Professors:")
    for p in professors[:5]: # Show top 5
        print(f"   ğŸ‘¨â€ğŸ« {p.get('name')} ({p.get('email')})")
        print(f"       Lab: {p.get('lab_name')}")
        print(f"       Areas: {p.get('research_areas')}")
        print("---")

if __name__ == "__main__":
    asyncio.run(main())
