"""
ChromaDB ë²¡í„° ì €ì¥ì†Œì— ë…¼ë¬¸ë“¤ì„ ìƒ‰ì¸(indexing)í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸

ë¶„ì„ëœ ë…¼ë¬¸ë“¤ì„ ChromaDBì— ì €ì¥í•˜ì—¬ ë²¡í„° ê²€ìƒ‰ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.

ì‹¤í–‰: python run_chromadb_indexing.py
"""

import sys
from datetime import datetime

# SQLAlchemy
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

# Domain
from src.domain.models import (
    ResearchPaper, PaperAnalysis
)

# Services
from src.services.vector_store import VectorStore
from src.core.logging import get_logger, setup_logging

# Logging
setup_logging(level="INFO")
logger = get_logger(__name__)

# Database setup
DATABASE_URL = "sqlite:///./univ_insight.db"
engine = create_engine(DATABASE_URL, echo=False)
SessionLocal = sessionmaker(bind=engine)


def index_papers_to_chromadb():
    """ë¶„ì„ëœ ë…¼ë¬¸ë“¤ì„ ChromaDBì— ìƒ‰ì¸"""
    logger.info("\n" + "="*70)
    logger.info("ğŸ—‚ï¸ ChromaDB ë²¡í„° ì €ì¥ì†Œ ìƒ‰ì¸ ì‹œì‘")
    logger.info("="*70)

    session = SessionLocal()
    vector_store = VectorStore(
        persist_dir="./chroma_db",
        persist_enabled=True,
        collection_name="research_papers"
    )

    try:
        # 1ï¸âƒ£ ë¶„ì„ëœ ë…¼ë¬¸ ì¡°íšŒ
        papers_with_analysis = session.query(ResearchPaper).filter(
            ResearchPaper.analysis != None
        ).all()

        if not papers_with_analysis:
            logger.info("âŒ ë¶„ì„ëœ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤\n")
            return

        logger.info(f"ğŸ“‹ ìƒ‰ì¸í•  ë…¼ë¬¸: {len(papers_with_analysis)}ê°œ\n")

        # 2ï¸âƒ£ ê¸°ì¡´ ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”
        current_count = vector_store.get_collection_count()
        if current_count > 0:
            logger.info(f"ğŸ—‘ï¸ ê¸°ì¡´ ë²¡í„° {current_count}ê°œ ì‚­ì œ ì¤‘...")
            vector_store.clear_collection()
            logger.info("âœ… ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì™„ë£Œ\n")

        # 3ï¸âƒ£ ê° ë…¼ë¬¸ì„ ë²¡í„° ì €ì¥ì†Œì— ì¶”ê°€
        indexed_count = 0
        for idx, paper in enumerate(papers_with_analysis, 1):
            try:
                # ìƒ‰ì¸í•  ì½˜í…ì¸  ì¤€ë¹„
                # ì œëª©, ìš”ì•½, ê¸°ìˆ  ìŠ¤íƒ, ê¸°ì—…, ì§ì—… ì •ë³´ í¬í•¨
                analysis = paper.analysis

                content = f"""
                Title: {paper.title}

                Summary: {analysis.easy_summary}

                Technologies: {', '.join(analysis.core_technologies[:5])}

                Companies: {', '.join(analysis.recommended_companies[:5])}

                Jobs: {', '.join(analysis.job_roles)}

                Subjects: {', '.join(analysis.recommended_subjects[:5])}
                """.strip()

                # ë©”íƒ€ë°ì´í„° ì¤€ë¹„ (ChromaDBëŠ” ì œí•œëœ íƒ€ì… ì§€ì›)
                metadata = {
                    "title": str(paper.title)[:512],  # String
                    "lab_id": str(paper.lab_id),  # String
                    "venue": str(paper.venue or "Unknown")[:256],  # String
                    "publication_year": int(paper.publication_year or 2024),  # Integer
                    "companies": str(",".join(analysis.recommended_companies[:3]))[:256],  # String
                    "jobs": str(",".join(analysis.job_roles))[:256],  # String
                    "technologies": str(",".join(analysis.core_technologies[:5]))[:256],  # String
                    "salary_range": str(analysis.salary_range or "Not specified")[:100],  # String
                    "analysis_model": str(analysis.analysis_model or "Unknown")[:100]  # String
                }

                # ë²¡í„° ì €ì¥ì†Œì— ì¶”ê°€
                vector_store.add_embedding(
                    paper_id=paper.id,
                    content=content,
                    metadata=metadata
                )

                indexed_count += 1
                logger.info(f"[{idx}/{len(papers_with_analysis)}] âœ… ìƒ‰ì¸ë¨: {paper.title[:60]}...")

            except Exception as e:
                logger.error(f"[{idx}/{len(papers_with_analysis)}] âŒ ìƒ‰ì¸ ì‹¤íŒ¨: {str(e)[:100]}")
                continue

        logger.info("")
        logger.info("="*70)
        logger.info(f"âœ… ìƒ‰ì¸ ì™„ë£Œ: {indexed_count}/{len(papers_with_analysis)}ê°œ ë…¼ë¬¸")
        logger.info("="*70)

        # 4ï¸âƒ£ ìµœì¢… í†µê³„
        final_count = vector_store.get_collection_count()
        logger.info(f"\nğŸ“Š ë²¡í„° ì €ì¥ì†Œ í†µê³„:")
        logger.info(f"   - ìƒ‰ì¸ëœ ë…¼ë¬¸: {final_count}ê°œ")
        logger.info(f"   - ì €ì¥ ìœ„ì¹˜: ./chroma_db")
        logger.info(f"   - ì»¬ë ‰ì…˜ëª…: research_papers")
        logger.info(f"   - ìƒ‰ì¸ ëª¨ë¸: nomic-embed-text (ChromaDB ê¸°ë³¸)\n")

    finally:
        session.close()


def test_vector_search():
    """ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
    logger.info("="*70)
    logger.info("ğŸ” ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    logger.info("="*70 + "\n")

    vector_store = VectorStore(
        persist_dir="./chroma_db",
        persist_enabled=True
    )

    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
    test_queries = [
        "AI and deep learning research",
        "Autonomous vehicles and computer vision",
        "Distributed systems and cloud computing",
        "Job opportunities in technology"
    ]

    for query in test_queries:
        logger.info(f"ğŸ” ê²€ìƒ‰: '{query}'")

        results = vector_store.search(query, k=3, threshold=0.0)

        if not results:
            logger.info("   âŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ\n")
            continue

        for idx, result in enumerate(results, 1):
            logger.info(f"   [{idx}] {result['id']}")
            logger.info(f"       ì œëª©: {result['metadata'].get('title', 'Unknown')[:60]}")
            logger.info(f"       ìœ ì‚¬ë„: {result['similarity']:.3f}")
            logger.info(f"       íšŒì‚¬: {result['metadata'].get('companies', 'N/A')}")
            logger.info(f"       ì§ì—…: {result['metadata'].get('jobs', 'N/A')}")

        logger.info("")


def verify_chromadb_status():
    """ChromaDB ìƒíƒœ í™•ì¸"""
    logger.info("="*70)
    logger.info("ğŸ“ˆ ChromaDB ìƒíƒœ í™•ì¸")
    logger.info("="*70 + "\n")

    vector_store = VectorStore(
        persist_dir="./chroma_db",
        persist_enabled=True
    )

    count = vector_store.get_collection_count()

    logger.info(f"âœ… ë²¡í„° ì €ì¥ì†Œ ìƒíƒœ:")
    logger.info(f"   - ì €ì¥ì†Œ: ChromaDB (Persistent)")
    logger.info(f"   - ìœ„ì¹˜: ./chroma_db")
    logger.info(f"   - ì»¬ë ‰ì…˜: research_papers")
    logger.info(f"   - ìƒ‰ì¸ëœ ë¬¸ì„œ: {count}ê°œ")
    logger.info(f"   - ì„ë² ë”© ëª¨ë¸: nomic-embed-text (ê¸°ë³¸)")
    logger.info(f"   - ìœ ì‚¬ë„ ë©”íŠ¸ë¦­: cosine similarity")
    logger.info(f"   - ìƒíƒœ: {'ğŸŸ¢ Ready' if count > 0 else 'ğŸ”´ Empty'}\n")


if __name__ == "__main__":
    logger.info("\n" + "="*70)
    logger.info("ğŸš€ ChromaDB ë²¡í„° ì €ì¥ì†Œ êµ¬ì¶• íŒŒì´í”„ë¼ì¸")
    logger.info("="*70)

    # ë…¼ë¬¸ ìƒ‰ì¸
    index_papers_to_chromadb()

    # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    test_vector_search()

    # ìƒíƒœ í™•ì¸
    verify_chromadb_status()

    logger.info("="*70)
    logger.info("âœ¨ ChromaDB êµ¬ì¶• ì™„ë£Œ!")
    logger.info("="*70 + "\n")
