"""
Ollama LLMì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ë…¼ë¬¸ ë¶„ì„ ìˆ˜í–‰

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ”:
1. ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ì˜ ë…¼ë¬¸ë“¤ì„ ë¡œë“œ
2. Ollama LLMìœ¼ë¡œ ê° ë…¼ë¬¸ì„ ë¶„ì„
3. PaperAnalysis í…Œì´ë¸”ì— ì‹¤ì œ ë¶„ì„ ê²°ê³¼ ì €ì¥

ì‹¤í–‰: python run_ollama_analysis.py
"""

import sys
import json
import re
from datetime import datetime
import uuid

# SQLAlchemy
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

# Domain
from src.domain.models import (
    Base, ResearchPaper, PaperAnalysis
)

# Services
from src.services.llm import OllamaLLM
from src.core.logging import get_logger, setup_logging

# Logging
setup_logging(level="INFO")
logger = get_logger(__name__)

# Database setup
DATABASE_URL = "sqlite:///./univ_insight.db"
engine = create_engine(DATABASE_URL, echo=False)
SessionLocal = sessionmaker(bind=engine)


def analyze_papers_with_ollama():
    """Ollama LLMìœ¼ë¡œ ë…¼ë¬¸ ë¶„ì„"""
    logger.info("\n" + "="*70)
    logger.info("ğŸ¤– Ollama LLMì„ ì‚¬ìš©í•œ ë…¼ë¬¸ ë¶„ì„ ì‹œì‘")
    logger.info("="*70)

    session = SessionLocal()

    try:
        # 1ï¸âƒ£ ë¶„ì„ë˜ì§€ ì•Šì€ ë…¼ë¬¸ ì¡°íšŒ
        papers = session.query(ResearchPaper).filter(
            ResearchPaper.analysis == None
        ).all()

        if not papers:
            logger.info("ğŸ“„ ë¶„ì„í•  ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        logger.info(f"ğŸ“‹ ë¶„ì„í•  ë…¼ë¬¸: {len(papers)}ê°œ")
        logger.info("")

        # 2ï¸âƒ£ Ollama LLM ì´ˆê¸°í™”
        try:
            llm = OllamaLLM(model="llama2:latest")
            logger.info("âœ… Ollama LLM ì—°ê²° ì„±ê³µ (llama2:latest)\n")
        except Exception as e:
            logger.error(f"âŒ Ollama ì—°ê²° ì‹¤íŒ¨: {e}")
            logger.info("ğŸ’¡ í•´ê²°ì±…: ollama serveë¥¼ ì‹¤í–‰í•˜ì„¸ìš”")
            return

        # 3ï¸âƒ£ ê° ë…¼ë¬¸ ë¶„ì„
        analyzed_count = 0
        for idx, paper in enumerate(papers, 1):
            logger.info(f"[{idx}/{len(papers)}] ë…¼ë¬¸ ë¶„ì„ ì¤‘: {paper.title[:50]}...")

            try:
                # Ollamaë¡œ ë¶„ì„
                analysis_result = llm.analyze(paper)

                # PaperAnalysis ê°ì²´ ìƒì„± (ìƒˆë¡œìš´ schemaì— ë§ì¶¤)
                analysis = PaperAnalysis(
                    id=str(uuid.uuid4()),
                    paper_id=paper.id,

                    # Summary
                    easy_summary=analysis_result.research_summary,
                    technical_summary=f"Advanced analysis based on {paper.venue or 'research'}",

                    # Core technologies
                    core_technologies=_extract_technologies(analysis_result.research_summary),
                    required_skills=["Programming", "Mathematics", "Data Analysis"],
                    math_concepts=["Linear Algebra", "Statistics", "Calculus"],

                    # Application
                    application_fields=["Artificial Intelligence", "Technology", "Industry"],
                    industry_relevance="Highly relevant for tech companies and AI startups",

                    # Career
                    career_paths=analysis_result.career_path.companies,
                    recommended_companies=analysis_result.career_path.companies,
                    salary_range=analysis_result.career_path.avg_salary_hint,
                    job_roles=[analysis_result.career_path.job_title],

                    # Study plan
                    recommended_subjects=analysis_result.action_item.subjects,
                    action_items={
                        "research_topic": analysis_result.action_item.research_topic,
                        "subjects": analysis_result.action_item.subjects
                    },
                    learning_path=_create_learning_path(
                        analysis_result.action_item.subjects
                    ),

                    # Metadata
                    analysis_model="llama2:latest"
                )

                session.add(analysis)
                session.commit()

                analyzed_count += 1
                logger.info(f"   âœ… ë¶„ì„ ì™„ë£Œ: {analysis_result.title}")
                logger.info(f"   ğŸ“Œ ì§ì—…: {analysis_result.career_path.job_title}")
                logger.info(f"   ğŸ¢ ì¶”ì²œ ê¸°ì—…: {', '.join(analysis_result.career_path.companies[:3])}")
                logger.info("")

            except Exception as e:
                logger.error(f"   âŒ ë¶„ì„ ì‹¤íŒ¨: {str(e)[:100]}")
                logger.info("")
                continue

        logger.info("="*70)
        logger.info(f"âœ… ë¶„ì„ ì™„ë£Œ: {analyzed_count}/{len(papers)}ê°œ ë…¼ë¬¸")
        logger.info("="*70)

    finally:
        session.close()


def _extract_technologies(summary: str) -> list:
    """ìš”ì•½ì—ì„œ ê¸°ìˆ  ì¶”ì¶œ"""
    tech_keywords = [
        "transformer", "neural", "deep learning", "ai", "machine learning",
        "pytorch", "tensorflow", "cuda", "optimization", "algorithm",
        "nlp", "computer vision", "cv", "llm", "language model",
        "encoder", "decoder", "attention", "bert", "gpt"
    ]

    summary_lower = summary.lower()
    found_techs = [
        tech.title() for tech in tech_keywords
        if tech in summary_lower
    ]

    return found_techs if found_techs else ["Advanced AI Technology"]


def _create_learning_path(subjects: list) -> list:
    """í•™ìŠµ ê²½ë¡œ ìƒì„±"""
    return [
        {
            "step": 1,
            "title": "ê¸°ì´ˆ ìˆ˜í•™",
            "subjects": ["ë¯¸ì ë¶„", "ì„ í˜•ëŒ€ìˆ˜"],
            "duration": "1-2ê°œì›”"
        },
        {
            "step": 2,
            "title": "í”„ë¡œê·¸ë˜ë° ê¸°ì´ˆ",
            "subjects": ["Python", "C++"],
            "duration": "2-3ê°œì›”"
        },
        {
            "step": 3,
            "title": "ë¨¸ì‹ ëŸ¬ë‹ ê¸°ì´ˆ",
            "subjects": subjects[:2] if subjects else ["ì‹¬í™” ìˆ˜í•™", "í†µê³„í•™"],
            "duration": "2-3ê°œì›”"
        },
        {
            "step": 4,
            "title": "ì‹¬í™” ì£¼ì œ",
            "subjects": subjects[2:] if len(subjects) > 2 else ["ê³ ê¸‰ ì•Œê³ ë¦¬ì¦˜"],
            "duration": "3-6ê°œì›”"
        }
    ]


def verify_analysis():
    """ë¶„ì„ ê²°ê³¼ ê²€ì¦"""
    logger.info("\n" + "="*70)
    logger.info("ğŸ“Š ë¶„ì„ ê²°ê³¼ ê²€ì¦")
    logger.info("="*70)

    session = SessionLocal()

    try:
        papers_with_analysis = session.query(PaperAnalysis).all()

        if not papers_with_analysis:
            logger.info("âŒ ë¶„ì„ëœ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤")
            return

        logger.info(f"âœ… ë¶„ì„ëœ ë…¼ë¬¸: {len(papers_with_analysis)}ê°œ\n")

        for analysis in papers_with_analysis:
            paper = analysis.paper
            logger.info(f"ğŸ“„ {paper.title}")
            logger.info(f"   ğŸ“ ìš”ì•½: {analysis.easy_summary[:80]}...")
            logger.info(f"   ğŸ’¼ ì§ì—…: {', '.join(analysis.job_roles)}")
            logger.info(f"   ğŸ¢ ê¸°ì—…: {', '.join(analysis.recommended_companies[:2])}")
            logger.info(f"   ğŸ“š ê³¼ëª©: {', '.join(analysis.recommended_subjects)}")
            logger.info(f"   ğŸ’° ì—°ë´‰: {analysis.salary_range}")
            logger.info(f"   ğŸ¤– ëª¨ë¸: {analysis.analysis_model}")
            logger.info("")

    finally:
        session.close()


if __name__ == "__main__":
    logger.info("\nğŸš€ Ollama ê¸°ë°˜ ë…¼ë¬¸ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹œì‘\n")

    # ë…¼ë¬¸ ë¶„ì„ ìˆ˜í–‰
    analyze_papers_with_ollama()

    # ê²°ê³¼ ê²€ì¦
    verify_analysis()

    logger.info("\nâœ¨ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
