"""
Ollama LLMìœ¼ë¡œ ë…¼ë¬¸ì„ ë‹¤ì‹œ ë¶„ì„í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸

ê¸°ì¡´ ë¶„ì„ì„ ì‚­ì œí•˜ê³  ì‹¤ì œ Ollama LLMìœ¼ë¡œ ë‹¤ì‹œ ë¶„ì„í•©ë‹ˆë‹¤.

ì‹¤í–‰: python run_ollama_reanalysis.py
"""

import sys
import json
import re
from datetime import datetime
import uuid

# SQLAlchemy
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

# Domain
from src.domain.models import (
    Base, ResearchPaper, PaperAnalysis
)

# Services
from src.services.llm import OllamaLLM
from src.core.logging import get_logger, setup_logging

# Logging
setup_logging(level="INFO")
logger = get_logger(__name__)

# Database setup
DATABASE_URL = "sqlite:///./univ_insight.db"
engine = create_engine(DATABASE_URL, echo=False)
SessionLocal = sessionmaker(bind=engine)


def clear_existing_analysis():
    """ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ ì‚­ì œ"""
    logger.info("\n" + "="*70)
    logger.info("ğŸ—‘ï¸ ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ ì‚­ì œ ì¤‘...")
    logger.info("="*70)

    session = SessionLocal()

    try:
        count = session.query(PaperAnalysis).delete()
        session.commit()
        logger.info(f"âœ… {count}ê°œì˜ ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ ì‚­ì œ\n")
    finally:
        session.close()


def analyze_papers_with_ollama():
    """Ollama LLMìœ¼ë¡œ ë…¼ë¬¸ ë¶„ì„"""
    logger.info("="*70)
    logger.info("ğŸ¤– Ollama LLMì„ ì‚¬ìš©í•œ ë…¼ë¬¸ ë¶„ì„ ì‹œì‘")
    logger.info("="*70)

    session = SessionLocal()

    try:
        # 1ï¸âƒ£ ëª¨ë“  ë…¼ë¬¸ ì¡°íšŒ
        papers = session.query(ResearchPaper).all()

        if not papers:
            logger.info("ğŸ“„ ë¶„ì„í•  ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        logger.info(f"ğŸ“‹ ë¶„ì„í•  ë…¼ë¬¸: {len(papers)}ê°œ")
        logger.info("")

        # 2ï¸âƒ£ Ollama LLM ì´ˆê¸°í™”
        try:
            llm = OllamaLLM(model="llama2:latest")
            logger.info("âœ… Ollama LLM ì—°ê²° ì„±ê³µ (llama2:latest)\n")
        except Exception as e:
            logger.error(f"âŒ Ollama ì—°ê²° ì‹¤íŒ¨: {e}")
            logger.info("ğŸ’¡ í•´ê²°ì±…: ollama serveë¥¼ ë‹¤ë¥¸ í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”\n")
            return

        # 3ï¸âƒ£ ê° ë…¼ë¬¸ ë¶„ì„
        analyzed_count = 0
        failed_count = 0

        for idx, paper in enumerate(papers, 1):
            logger.info(f"[{idx}/{len(papers)}] ë¶„ì„ ì¤‘: {paper.title[:50]}...")

            try:
                # Ollamaë¡œ ë¶„ì„ (ì‹¤ì œ LLM í˜¸ì¶œ)
                logger.info(f"   ğŸ“ Ollama í˜¸ì¶œ ì¤‘...")
                analysis_result = llm.analyze(paper)

                # PaperAnalysis ê°ì²´ ìƒì„±
                analysis = PaperAnalysis(
                    id=str(uuid.uuid4()),
                    paper_id=paper.id,

                    # Summary
                    easy_summary=analysis_result.research_summary,
                    technical_summary=f"Technical analysis of {paper.title}",

                    # Core technologies
                    core_technologies=_extract_technologies(analysis_result.research_summary),
                    required_skills=["Programming", "Mathematics", "Data Analysis", "System Design"],
                    math_concepts=["Linear Algebra", "Statistics", "Calculus", "Probability"],

                    # Application
                    application_fields=["Technology", "Industry Applications", "Research"],
                    industry_relevance=_generate_industry_relevance(
                        paper.title,
                        analysis_result.career_path.companies
                    ),

                    # Career
                    career_paths=analysis_result.career_path.companies,
                    recommended_companies=analysis_result.career_path.companies,
                    salary_range=analysis_result.career_path.avg_salary_hint,
                    job_roles=[analysis_result.career_path.job_title] if analysis_result.career_path.job_title else ["AI Engineer"],

                    # Study plan
                    recommended_subjects=analysis_result.action_item.subjects if analysis_result.action_item.subjects else ["Advanced Mathematics"],
                    action_items={
                        "research_topic": analysis_result.action_item.research_topic if analysis_result.action_item.research_topic else "Research continuation",
                        "subjects": analysis_result.action_item.subjects if analysis_result.action_item.subjects else []
                    },
                    learning_path=_create_learning_path(
                        analysis_result.action_item.subjects if analysis_result.action_item.subjects else ["Advanced Topics"]
                    ),

                    # Metadata
                    analysis_model="llama2:latest"
                )

                session.add(analysis)
                session.commit()

                analyzed_count += 1

                # ê²°ê³¼ ì¶œë ¥
                logger.info(f"   âœ… ë¶„ì„ ì™„ë£Œ!")
                logger.info(f"   ğŸ“Œ ì§ì—…: {analysis_result.career_path.job_title}")
                logger.info(f"   ğŸ¢ íšŒì‚¬: {', '.join(analysis_result.career_path.companies[:2])}")
                logger.info(f"   ğŸ“ ìš”ì•½: {analysis_result.research_summary[:60]}...")
                logger.info("")

            except Exception as e:
                failed_count += 1
                logger.error(f"   âŒ ë¶„ì„ ì‹¤íŒ¨: {str(e)[:100]}")
                logger.info("")
                # ì‹¤íŒ¨í•œ ê²½ìš°ë„ ê³„ì† ì§„í–‰
                continue

        logger.info("="*70)
        logger.info(f"âœ… ë¶„ì„ ì™„ë£Œ: {analyzed_count}ê°œ ì„±ê³µ, {failed_count}ê°œ ì‹¤íŒ¨")
        logger.info("="*70)

        # ìµœì¢… í†µê³„
        total_analysis = session.query(PaperAnalysis).count()
        logger.info(f"\nğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ í˜„í™©:")
        logger.info(f"   - ì´ ë…¼ë¬¸: {session.query(ResearchPaper).count()}ê°œ")
        logger.info(f"   - ë¶„ì„ëœ ë…¼ë¬¸: {total_analysis}ê°œ")
        logger.info(f"   - ë¶„ì„ ì™„ë£Œìœ¨: {(total_analysis/len(papers)*100):.1f}%\n")

    finally:
        session.close()


def _extract_technologies(summary: str) -> list:
    """ìš”ì•½ì—ì„œ ê¸°ìˆ  ì¶”ì¶œ"""
    tech_keywords = [
        "transformer", "neural", "deep learning", "ai", "machine learning",
        "pytorch", "tensorflow", "cuda", "optimization", "algorithm",
        "nlp", "computer vision", "cv", "llm", "language model",
        "encoder", "decoder", "attention", "bert", "gpt", "distributed",
        "cloud", "system", "network", "database", "compiler"
    ]

    summary_lower = summary.lower()
    found_techs = [
        tech.title() for tech in tech_keywords
        if tech in summary_lower
    ]

    if not found_techs:
        found_techs = ["Advanced Technology"]

    return found_techs[:5]  # ìµœëŒ€ 5ê°œ


def _generate_industry_relevance(title: str, companies: list) -> str:
    """ì‚°ì—… ê´€ë ¨ì„± ìƒì„±"""
    if not companies:
        return "Relevant for technology sector and AI industry"

    return f"Highly relevant for {', '.join(companies[:2])} and similar technology companies"


def _create_learning_path(subjects: list) -> list:
    """í•™ìŠµ ê²½ë¡œ ìƒì„±"""
    base_path = [
        {
            "step": 1,
            "title": "ê¸°ì´ˆ ì´ë¡ ",
            "subjects": ["ë¯¸ì ë¶„", "ì„ í˜•ëŒ€ìˆ˜", "í™•ë¥ í†µê³„"],
            "duration": "1-2ê°œì›”",
            "focus": "Mathematical foundations"
        },
        {
            "step": 2,
            "title": "í”„ë¡œê·¸ë˜ë° ê¸°ì´ˆ",
            "subjects": ["Python", "C++", "Java"],
            "duration": "2-3ê°œì›”",
            "focus": "Programming fundamentals"
        },
        {
            "step": 3,
            "title": "ì „ê³µ ê¸°ì´ˆ",
            "subjects": subjects[:3] if subjects else ["Advanced Mathematics", "Algorithms"],
            "duration": "2-3ê°œì›”",
            "focus": "Domain-specific knowledge"
        },
        {
            "step": 4,
            "title": "ì‹¬í™” í•™ìŠµ",
            "subjects": subjects[3:] if len(subjects) > 3 else ["Research Topics"],
            "duration": "3-6ê°œì›”",
            "focus": "Advanced topics and research"
        }
    ]

    return base_path


def verify_analysis():
    """ë¶„ì„ ê²°ê³¼ ê²€ì¦ ë° ì¶œë ¥"""
    logger.info("\n" + "="*70)
    logger.info("ğŸ“Š ë¶„ì„ ê²°ê³¼ ê²€ì¦")
    logger.info("="*70 + "\n")

    session = SessionLocal()

    try:
        papers_with_analysis = session.query(PaperAnalysis).all()

        if not papers_with_analysis:
            logger.info("âŒ ë¶„ì„ëœ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤\n")
            return

        logger.info(f"âœ… ì´ {len(papers_with_analysis)}ê°œ ë…¼ë¬¸ ë¶„ì„ ì™„ë£Œ\n")

        for idx, analysis in enumerate(papers_with_analysis, 1):
            paper = analysis.paper
            logger.info(f"[{idx}] {paper.title}")
            logger.info(f"   ğŸ“ ìš”ì•½: {analysis.easy_summary[:80]}...")
            logger.info(f"   ğŸ’¼ ì§ì—…: {', '.join(analysis.job_roles)}")
            logger.info(f"   ğŸ¢ ê¸°ì—…: {', '.join(analysis.recommended_companies[:2])}")
            logger.info(f"   ğŸ“š ê³¼ëª©: {', '.join(analysis.recommended_subjects[:3])}")
            logger.info(f"   ğŸ’° ì—°ë´‰: {analysis.salary_range}")
            logger.info(f"   ğŸ¤– ëª¨ë¸: {analysis.analysis_model}")
            logger.info("")

    finally:
        session.close()


if __name__ == "__main__":
    logger.info("\n" + "="*70)
    logger.info("ğŸš€ Ollama LLM ê¸°ë°˜ ë…¼ë¬¸ ì¬ë¶„ì„ íŒŒì´í”„ë¼ì¸")
    logger.info("="*70)

    # ê¸°ì¡´ ë¶„ì„ ì‚­ì œ
    clear_existing_analysis()

    # ë…¼ë¬¸ ë¶„ì„ ìˆ˜í–‰
    analyze_papers_with_ollama()

    # ê²°ê³¼ ê²€ì¦
    verify_analysis()

    logger.info("="*70)
    logger.info("âœ¨ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
    logger.info("="*70 + "\n")
