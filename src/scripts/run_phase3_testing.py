"""
Phase 3 í…ŒìŠ¤íŠ¸: RAG + LLM ë¶„ì„ + ì¶”ì²œ ì—”ì§„

êµ¬í˜„ ì‚¬í•­:
1. ë²¡í„° ìŠ¤í† ì–´ (ChromaDB)
2. RAG ì—”ì§„
3. LLM ë¶„ì„
4. ì¶”ì²œ ì—”ì§„
"""

import asyncio
import json
import logging
from datetime import datetime

from src.services.vector_store import ChromaVectorStore, EmbeddingService
from src.services.rag_engine import RAGEngine
from src.services.llm_analysis import LLMAnalysisService
from src.services.recommendation_engine import RecommendationEngine

logging.basicConfig(
    level=logging.INFO,
    format='%(message)s'
)
logger = logging.getLogger(__name__)


async def test_phase3():
    """Phase 3 í…ŒìŠ¤íŠ¸"""

    print("\n" + "="*80)
    print("ğŸš€ Phase 3 í…ŒìŠ¤íŠ¸: RAG + LLM ë¶„ì„ + ì¶”ì²œ ì—”ì§„")
    print("="*80 + "\n")

    # 1ï¸âƒ£ ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”
    print("ğŸ“š ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”...")
    embedding_service = EmbeddingService()
    vector_store = ChromaVectorStore(
        collection_name="phase3_test",
        persist_dir="./chroma_db_phase3",
        embedding_service=embedding_service,
    )
    await vector_store.initialize()
    print()

    # 2ï¸âƒ£ í…ŒìŠ¤íŠ¸ ë…¼ë¬¸ ë°ì´í„° ì¶”ê°€
    print("ğŸ“„ í…ŒìŠ¤íŠ¸ ë…¼ë¬¸ ë°ì´í„° ì¶”ê°€...")
    test_papers = [
        {
            "id": "paper-1",
            "title": "íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ ìµœì í™”: ì—ë„ˆì§€ íš¨ìœ¨ì„± ê°œì„ ",
            "content": """íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” í˜„ëŒ€ AIì˜ í•µì‹¬ ì•„í‚¤í…ì²˜ì…ë‹ˆë‹¤. ì´ ë…¼ë¬¸ì€ ìê¸° ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜(self-attention)ì˜ ê³„ì‚° ë³µì¡ë„ë¥¼ ì¤„ì´ëŠ” ë°©ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤. 
            ê¸°ì¡´ íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” O(nÂ²)ì˜ ì‹œê°„ ë³µì¡ë„ë¥¼ ê°€ì§€ê³  ìˆì–´ ê¸´ ì‹œí€€ìŠ¤ ì²˜ë¦¬ ì‹œ ë§ì€ ì—ë„ˆì§€ë¥¼ ì†Œë¹„í•©ë‹ˆë‹¤.
            ìš°ë¦¬ì˜ ë°©ë²•ì€ ì„ í˜• ì–´í…ì…˜(linear attention)ì„ ì‚¬ìš©í•˜ì—¬ O(n) ë³µì¡ë„ë¡œ ê°œì„ í–ˆìœ¼ë©°, ì‹¤í—˜ ê²°ê³¼ ì—ë„ˆì§€ ì†Œë¹„ë¥¼ 70% ê°ì†Œì‹œì¼°ìŠµë‹ˆë‹¤.
            ì´ëŠ” ëª¨ë°”ì¼ ì¥ì¹˜ì—ì„œ AI ëª¨ë¸ì„ ì‹¤í–‰í•  ë•Œ ë°°í„°ë¦¬ ìˆ˜ëª…ì„ í¬ê²Œ ì—°ì¥ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.""",
            "metadata": {
                "university": "KAIST",
                "department": "ì „ìê³µí•™ê³¼",
                "year": 2024,
            }
        },
        {
            "id": "paper-2",
            "title": "ììœ¨ì£¼í–‰ ìë™ì°¨ì˜ ë¼ì´ë‹¤ ì„¼ì„œ ìœµí•© ê¸°ìˆ ",
            "content": """ììœ¨ì£¼í–‰ ìë™ì°¨ëŠ” ì—¬ëŸ¬ ì„¼ì„œë¥¼ í†µí•©í•˜ì—¬ ì£¼ë³€ í™˜ê²½ì„ ì´í•´í•©ë‹ˆë‹¤.
            ë¼ì´ë‹¤(LiDAR)ëŠ” ë¹›ì„ ì´ìš©í•˜ì—¬ 3D ì •ë³´ë¥¼ ì–»ëŠ” í•µì‹¬ ì„¼ì„œì…ë‹ˆë‹¤.
            ì´ ë…¼ë¬¸ì€ ë¼ì´ë‹¤ì™€ ì¹´ë©”ë¼ ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ìœµí•©í•˜ëŠ” ì‹ ê²½ë§ ì•„í‚¤í…ì²˜ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.
            ì‹¤ì œ ë„ë¡œ í™˜ê²½ì—ì„œ í…ŒìŠ¤íŠ¸í•œ ê²°ê³¼, ê¸°ì¡´ ë°©ë²• ëŒ€ë¹„ 95% ì´ìƒì˜ ì •í™•ë„ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.
            íŠ¹íˆ ì•…ì²œí›„ ì¡°ê±´ì—ì„œì˜ ì„±ëŠ¥ì´ í¬ê²Œ ê°œì„ ë˜ì–´ ì•ˆì „ì„±ì„ ë†’ì˜€ìŠµë‹ˆë‹¤.""",
            "metadata": {
                "university": "ì„œìš¸ëŒ€í•™êµ",
                "department": "ê¸°ê³„í•­ê³µê³µí•™ê³¼",
                "year": 2024,
            }
        },
        {
            "id": "paper-3",
            "title": "mRNA ë°±ì‹  ê¸°ìˆ ì˜ ìµœì‹  ë°œì „: ê°œì¸ë§ì¶¤í˜• ì¹˜ë£Œ",
            "content": """mRNA ë°±ì‹ ì€ COVID-19 ì´í›„ ê°ê´‘ë°›ì€ ê¸°ìˆ ì…ë‹ˆë‹¤.
            ê¸°ì¡´ ë°±ì‹ ê³¼ ë‹¬ë¦¬ mRNAëŠ” ìš°ë¦¬ ëª¸ì˜ ì„¸í¬ë¥¼ ì´ìš©í•˜ì—¬ í•­ì›ì„ ì§ì ‘ ë§Œë“¤ê²Œ í•©ë‹ˆë‹¤.
            ì´ ë…¼ë¬¸ì€ ê°œì¸ì˜ ìœ ì „ ì •ë³´ì— ë§ì¶˜ ë§ì¶¤í˜• mRNA ë°±ì‹ ì„ ê°œë°œí•˜ëŠ” ë°©ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤.
            ì¢…ì–‘ í™˜ì ì„ìƒ ì‹œí—˜ì—ì„œ 70% ì´ìƒì˜ ë°˜ì‘ë¥ ì„ ë³´ì˜€ìœ¼ë©°, ë©´ì—­ ì²´ê³„ë¥¼ ê°•í™”í•˜ëŠ” íš¨ê³¼ê°€ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.
            ì´ ê¸°ìˆ ì€ ì•”, ì—ì´ì¦ˆ, ë§ë¼ë¦¬ì•„ ë“± ë‹¤ì–‘í•œ ì§ˆë³‘ ì¹˜ë£Œë¡œ í™•ëŒ€ë  ì „ë§ì…ë‹ˆë‹¤.""",
            "metadata": {
                "university": "ì„œìš¸ëŒ€í•™êµ",
                "department": "ìƒëª…ê³¼í•™ë¶€",
                "year": 2024,
            }
        },
    ]

    added = await vector_store.add_batch(test_papers)
    print(f"âœ… {added}ê°œ ë…¼ë¬¸ ì¶”ê°€ë¨\n")

    # 3ï¸âƒ£ RAG ì—”ì§„ ì´ˆê¸°í™”
    print("ğŸ” RAG ì—”ì§„ ì´ˆê¸°í™”...")
    rag_engine = RAGEngine(vector_store)
    print()

    # 4ï¸âƒ£ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    print("="*70)
    print("ğŸ” ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    print("="*70)

    queries = [
        "AI ëª¨ë¸ì˜ ì—ë„ˆì§€ íš¨ìœ¨",
        "ììœ¨ì£¼í–‰ ì„¼ì„œ ê¸°ìˆ ",
        "ì§ˆë³‘ ì¹˜ë£Œ ê¸°ìˆ ",
    ]

    search_results = {}
    for query in queries:
        print(f"\nğŸ“Œ ì¿¼ë¦¬: {query}")
        rag_result = await rag_engine.retrieve_and_rank(query, top_k=2)
        search_results[query] = rag_result
        print(f"   ì°¾ìŒ: {rag_result['context_count']}ê°œ ë…¼ë¬¸")
        for doc in rag_result["context_docs"]:
            print(f"     - {doc['title']} (ê±°ë¦¬: {doc['distance']:.3f})")

    print()

    # 5ï¸âƒ£ LLM ë¶„ì„
    print("="*70)
    print("ğŸ§  LLM ë¶„ì„")
    print("="*70)

    llm_service = LLMAnalysisService(llm_provider="mock")
    first_query = queries[0]
    rag_result = search_results[first_query]

    print(f"\nğŸ“ {first_query} ë¶„ì„ ì¤‘...")
    analysis = await llm_service.analyze_research_paper(rag_result["rag_prompt"])
    print(f"âœ… ë¶„ì„ ì™„ë£Œ\n")

    print("ë¶„ì„ ê²°ê³¼:")
    for key, value in analysis.items():
        if isinstance(value, list):
            print(f"  {key}:")
            for item in value:
                print(f"    - {item}")
        else:
            print(f"  {key}: {value}")

    print()

    # 6ï¸âƒ£ ì¶”ì²œ ì—”ì§„
    print("="*70)
    print("ğŸ’¼ ì¶”ì²œ ì—”ì§„")
    print("="*70)

    recommendation_engine = RecommendationEngine()

    print("\nğŸ“Œ ì£¼ì œ: AI ì—ë„ˆì§€ íš¨ìœ¨ì„±")
    roadmap = await recommendation_engine.generate_student_roadmap("AI/ë¨¸ì‹ ëŸ¬ë‹")

    print("\nì§„ë¡œ ì¶”ì²œ:")
    for career in roadmap["career_paths"]:
        print(f"  - {career['company']}: {career['job']} ({career['salary']})")

    print("\ní”Œëœ B ëŒ€í•™:")
    for uni in roadmap["plan_b_universities"]:
        print(f"  - {uni['university']} {uni['department']}")

    print("\nê´€ë ¨ ì£¼ì œ:")
    for topic in roadmap["related_topics"]:
        print(f"  - {topic}")

    print("\ní•™ìŠµ íƒ€ì„ë¼ì¸:")
    for grade, description in roadmap["timeline"].items():
        print(f"  {grade}: {description}")

    print()

    # 7ï¸âƒ£ í†µê³„
    print("="*70)
    print("ğŸ“Š ìµœì¢… í†µê³„")
    print("="*70)

    vector_stats = await vector_store.get_stats()
    rag_stats = await rag_engine.get_stats()
    rec_stats = await recommendation_engine.get_stats()

    print(f"\nğŸ“š ë²¡í„° ìŠ¤í† ì–´:")
    print(f"   ë¬¸ì„œ: {vector_stats['document_count']}ê°œ")
    print(f"   ëª¨ë¸: {vector_stats['embedding_model']}")

    print(f"\nğŸ” RAG ì—”ì§„:")
    print(f"   ìƒíƒœ: {rag_stats['rag_engine']}")

    print(f"\nğŸ’¼ ì¶”ì²œ ì—”ì§„:")
    print(f"   ëŒ€í•™: {rec_stats['universities_count']}ê°œ")
    print(f"   íšŒì‚¬: {rec_stats['companies_count']}ê°œ")

    # 8ï¸âƒ£ ê²°ê³¼ ì €ì¥
    print(f"\nğŸ“ ê²°ê³¼ ì €ì¥...")
    results = {
        "timestamp": datetime.now().isoformat(),
        "phase": "Phase 3",
        "test_results": {
            "vector_store": vector_stats,
            "search_queries": len(search_results),
            "queries": queries,
            "analysis": analysis,
            "recommendations": {
                "career_count": len(roadmap["career_paths"]),
                "universities_count": len(roadmap["plan_b_universities"]),
                "topics_count": len(roadmap["related_topics"]),
            },
        },
    }

    with open("PHASE3_TEST_REPORT.json", "w", encoding="utf-8") as f:
        json.dump(results, f, indent=2, ensure_ascii=False)

    print(f"âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: PHASE3_TEST_REPORT.json")

    print("\n" + "="*80)
    print("âœ… Phase 3 í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("="*80 + "\n")

    return results


if __name__ == "__main__":
    asyncio.run(test_phase3())
