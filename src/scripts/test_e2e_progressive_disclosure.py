#!/usr/bin/env python3
"""
Phase 2 Progressive Disclosure E2E Test
ì „ì²´ í”„ë¡œì„¸ìŠ¤ ê²€ì¦: í¬ë¡¤ë§ â†’ ë¶„ì„ â†’ ë¦¬í¬íŠ¸ ìƒì„±
"""

import sys
import os
sys.path.append(os.getcwd())

from src.core.database import SessionLocal
from src.domain.models import University, College, Department, Professor, Laboratory, ResearchPaper, PaperAnalysis, User, Report
from src.services.llm import OllamaLLM, MockLLM
from src.services.pdf_generator import PDFGenerator
from src.domain.schemas import ResearchPaper as SchemaResearchPaper
from datetime import datetime, date
import uuid

def test_e2e_progressive_disclosure():
    print("="*80)
    print("ğŸš€ Phase 2 Progressive Disclosure E2E Test")
    print("="*80)
    
    db = SessionLocal()
    
    try:
        # ==================== STEP 1: ë°ì´í„° ì¤€ë¹„ ====================
        print("\n[STEP 1] ë°ì´í„° ì¤€ë¹„ ì¤‘...")
        
        # University
        uni = db.query(University).filter(University.name == "Seoul National University").first()
        if not uni:
            print("âŒ SNU ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € í¬ë¡¤ë§ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
            return
            
        # Get professors
        profs = db.query(Professor).limit(3).all()
        if not profs:
            print("âŒ êµìˆ˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
            
        print(f"âœ… {len(profs)}ëª…ì˜ êµìˆ˜ ë°ì´í„° í™•ì¸")
        
        # ==================== STEP 2: ë…¼ë¬¸ ë¶„ì„ (LLM) ====================
        print("\n[STEP 2] ë…¼ë¬¸ ë¶„ì„ ì¤‘...")
        
        # Initialize LLM
        try:
            llm = OllamaLLM(model='qwen2:7b')
            print("   Using OllamaLLM")
        except:
            llm = MockLLM()
            print("   Using MockLLM (fallback)")
        
        analyzed_count = 0
        
        for prof in profs:
            print(f"\n   êµìˆ˜: {prof.name_ko}")
            
            # Find or create paper
            paper = None
            if prof.laboratories:
                for lab in prof.laboratories:
                    if lab.papers:
                        paper = lab.papers[0]
                        break
            
            if not paper:
                # Create virtual paper from research interests
                interests = ", ".join(prof.research_interests) if prof.research_interests else "General Research"
                paper = ResearchPaper(
                    id=f"virtual-{prof.id}",
                    lab_id=prof.laboratories[0].id if prof.laboratories else None,
                    title=f"{prof.name} êµìˆ˜ë‹˜ì˜ ì—°êµ¬: {interests}",
                    abstract=f"Research on {interests}",
                    url=f"virtual://{prof.id}",  # Unique URL for virtual papers
                    crawled_at=datetime.now()
                )
                db.add(paper)
                db.flush()
                print(f"   âœ… ê°€ìƒ ë…¼ë¬¸ ìƒì„±: {paper.title}")
            
            # Check if already analyzed
            existing_analysis = db.query(PaperAnalysis).filter(PaperAnalysis.paper_id == paper.id).first()
            if existing_analysis:
                print(f"   â­ï¸  ì´ë¯¸ ë¶„ì„ë¨, ìŠ¤í‚µ")
                analyzed_count += 1
                continue
            
            # Convert to schema
            schema_paper = SchemaResearchPaper(
                id=paper.id,
                url=paper.url or "",
                title=paper.title,
                university=uni.name,
                department=prof.department.name if prof.department else "Unknown",
                pub_date=paper.publication_date or date.today(),
                content_raw=paper.abstract or paper.title
            )
            
            # Analyze
            try:
                result = llm.analyze(schema_paper)
                print(f"   âœ… ë¶„ì„ ì™„ë£Œ: {result.topic_easy}")
                
                # Save to DB
                analysis = PaperAnalysis(
                    id=str(uuid.uuid4()),
                    paper_id=paper.id,
                    easy_summary=result.explanation,
                    technical_summary=f"Technical: {result.topic_technical}",
                    topic_easy=result.topic_easy,
                    topic_technical=result.topic_technical,
                    explanation=result.explanation,
                    reference_link=result.reference_link,
                    deep_dive={
                        "keywords": result.deep_dive.keywords,
                        "recommendations": result.deep_dive.recommendations,
                        "related_concepts": result.deep_dive.related_concepts
                    },
                    core_technologies=[],
                    required_skills=[],
                    math_concepts=result.deep_dive.related_concepts,
                    application_fields=[],
                    career_paths=result.career_path.companies,
                    recommended_companies=result.career_path.companies,
                    salary_range=result.career_path.avg_salary_hint,
                    job_roles=[result.career_path.job_title],
                    recommended_subjects=result.action_item.subjects,
                    action_items={"research_topic": result.action_item.research_topic},
                    learning_path=[],
                    analysis_model="qwen2:7b"
                )
                db.add(analysis)
                db.commit()
                analyzed_count += 1
                print(f"   ğŸ’¾ DB ì €ì¥ ì™„ë£Œ")
                
            except Exception as e:
                print(f"   âŒ ë¶„ì„ ì‹¤íŒ¨: {e}")
                db.rollback()
                continue
        
        print(f"\nâœ… ì´ {analyzed_count}ê°œ ë…¼ë¬¸ ë¶„ì„ ì™„ë£Œ")
        
        # ==================== STEP 3: ì‚¬ìš©ì ìƒì„± ====================
        print("\n[STEP 3] ì‚¬ìš©ì ìƒì„± ì¤‘...")
        
        user_id = "e2e-test-user"
        user = db.query(User).filter(User.id == user_id).first()
        if not user:
            user = User(
                id=user_id,
                name="í…ŒìŠ¤íŠ¸ í•™ìƒ",
                role="student",
                interests=["Computer Vision", "AI", "Robotics"]
            )
            db.add(user)
            db.commit()
            print(f"âœ… ì‚¬ìš©ì ìƒì„±: {user.name}")
        else:
            print(f"âœ… ê¸°ì¡´ ì‚¬ìš©ì ì‚¬ìš©: {user.name}")
        
        # ==================== STEP 4: ë¦¬í¬íŠ¸ ìƒì„± ====================
        print("\n[STEP 4] ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        
        # Get analyzed papers
        analyses = db.query(PaperAnalysis).join(ResearchPaper).limit(5).all()
        
        if not analyses:
            print("âŒ ë¶„ì„ëœ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"   {len(analyses)}ê°œì˜ ë¶„ì„ ê²°ê³¼ ì‚¬ìš©")
        
        # Prepare report data
        analysis_results = []
        for analysis in analyses:
            analysis_results.append({
                "topic_easy": analysis.topic_easy or "ì—°êµ¬ ì£¼ì œ",
                "topic_technical": analysis.topic_technical or "Technical Topic",
                "explanation": analysis.explanation or analysis.easy_summary,
                "reference_link": analysis.reference_link or "",
                "deep_dive": analysis.deep_dive or {
                    "keywords": [],
                    "recommendations": [],
                    "related_concepts": []
                },
                "career_path": {
                    "job_title": analysis.job_roles[0] if analysis.job_roles else "AI Engineer",
                    "companies": analysis.recommended_companies or [],
                    "avg_salary_hint": analysis.salary_range or "Unknown"
                },
                "action_item": {
                    "subjects": analysis.recommended_subjects or [],
                    "research_topic": analysis.action_items.get("research_topic", "") if analysis.action_items else ""
                },
                "professor_name": analysis.paper.laboratory.professor.name_ko if analysis.paper.laboratory and analysis.paper.laboratory.professor else "Unknown"
            })
        
        # Generate PDF
        pdf_gen = PDFGenerator(output_dir="docs/reports")
        report_data = {
            "user_name": user.name,
            "interests": ", ".join(user.interests),
            "report_date": datetime.now().strftime("%Y-%m-%d"),
            "analysis_results": analysis_results
        }
        
        pdf_path = pdf_gen.generate(report_data, "E2E_Progressive_Report.pdf")
        print(f"âœ… PDF ìƒì„± ì™„ë£Œ: {pdf_path}")
        
        # Save report to DB
        report = Report(
            id=str(uuid.uuid4()),
            user_id=user.id,
            status="sent",
            content=f"{len(analysis_results)}ê°œì˜ ì—°êµ¬ ë¶„ì„ í¬í•¨",
            report_type="career_guide_progressive",
            pdf_path=pdf_path
        )
        db.add(report)
        db.commit()
        print(f"âœ… ë¦¬í¬íŠ¸ DB ì €ì¥: {report.id}")
        
        # ==================== STEP 5: ê²€ì¦ ====================
        print("\n[STEP 5] ê²°ê³¼ ê²€ì¦ ì¤‘...")
        
        # Verify analysis count
        total_analyses = db.query(PaperAnalysis).count()
        print(f"   ì´ ë¶„ì„ ìˆ˜: {total_analyses}")
        
        # Verify report
        saved_report = db.query(Report).filter(Report.id == report.id).first()
        print(f"   ë¦¬í¬íŠ¸ ìƒíƒœ: {saved_report.status}")
        print(f"   PDF ê²½ë¡œ: {saved_report.pdf_path}")
        
        # Check Progressive Disclosure fields
        sample_analysis = db.query(PaperAnalysis).filter(PaperAnalysis.topic_easy.isnot(None)).first()
        if sample_analysis:
            print(f"\n   ğŸ“Š Progressive Disclosure í•„ë“œ í™•ì¸:")
            print(f"      - topic_easy: {sample_analysis.topic_easy}")
            print(f"      - topic_technical: {sample_analysis.topic_technical}")
            print(f"      - deep_dive keywords: {len(sample_analysis.deep_dive.get('keywords', []))} ê°œ")
        
        print("\n" + "="*80)
        print("âœ… E2E í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("="*80)
        print(f"\nğŸ“„ ìƒì„±ëœ ë¦¬í¬íŠ¸: {pdf_path}")
        print(f"ğŸ” ë¶„ì„ëœ ë…¼ë¬¸: {total_analyses}ê°œ")
        print(f"ğŸ‘¤ ì‚¬ìš©ì: {user.name} ({user.id})")
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        db.rollback()
    finally:
        db.close()

if __name__ == "__main__":
    test_e2e_progressive_disclosure()
