"""
ì›¹ í¬ë¡¤ë§ ì‘ë‹µ ìºì‹± ì„œë¹„ìŠ¤

ì£¼ìš” ê¸°ëŠ¥:
1. URLë³„ HTML ì‘ë‹µ ìºì‹±
2. ë©”ëª¨ë¦¬ ë° ë””ìŠ¤í¬ ìºì‹± ì§€ì›
3. TTL (Time To Live) ê¸°ë°˜ ìºì‹œ ë§Œë£Œ
4. ìë™ ìºì‹œ ì •ë¦¬
"""

import json
import logging
import hashlib
from pathlib import Path
from typing import Dict, Optional, Tuple
from datetime import datetime, timedelta
import threading

logger = logging.getLogger(__name__)


class CacheService:
    """ì›¹ í¬ë¡¤ë§ ì‘ë‹µ ìºì‹±"""

    def __init__(self, cache_dir: str = ".cache", ttl_hours: int = 24):
        """
        ì´ˆê¸°í™”

        Args:
            cache_dir: ìºì‹œ ë””ë ‰í† ë¦¬ ê²½ë¡œ
            ttl_hours: ìºì‹œ ìœ íš¨ ì‹œê°„ (ì‹œê°„ ë‹¨ìœ„)
        """
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        self.ttl_hours = ttl_hours
        self.memory_cache: Dict[str, Tuple[str, datetime]] = {}
        self.lock = threading.RLock()
        logger.info(f"ğŸš€ CacheService ì´ˆê¸°í™” (TTL={ttl_hours}ì‹œê°„, ê²½ë¡œ={cache_dir})")

    def get(self, url: str, use_disk: bool = True) -> Optional[str]:
        """
        ìºì‹œì—ì„œ ë°ì´í„° ì¡°íšŒ

        Args:
            url: ì¡°íšŒí•  URL
            use_disk: ë””ìŠ¤í¬ ìºì‹œ ì‚¬ìš© ì—¬ë¶€

        Returns:
            ìºì‹œëœ HTML ë˜ëŠ” None
        """
        cache_key = self._get_cache_key(url)

        # ë©”ëª¨ë¦¬ ìºì‹œ í™•ì¸
        with self.lock:
            if cache_key in self.memory_cache:
                html, timestamp = self.memory_cache[cache_key]
                if not self._is_expired(timestamp):
                    logger.debug(f"ğŸ“¦ ë©”ëª¨ë¦¬ ìºì‹œ hit: {url[:50]}...")
                    return html
                else:
                    del self.memory_cache[cache_key]

        # ë””ìŠ¤í¬ ìºì‹œ í™•ì¸
        if use_disk:
            cache_file = self.cache_dir / f"{cache_key}.json"
            if cache_file.exists():
                try:
                    with open(cache_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)

                    timestamp = datetime.fromisoformat(data['timestamp'])
                    if not self._is_expired(timestamp):
                        html = data['html']
                        # ë©”ëª¨ë¦¬ ìºì‹œì—ë„ ì €ì¥
                        with self.lock:
                            self.memory_cache[cache_key] = (html, timestamp)
                        logger.debug(f"ğŸ’¾ ë””ìŠ¤í¬ ìºì‹œ hit: {url[:50]}...")
                        return html
                    else:
                        cache_file.unlink()  # ë§Œë£Œëœ ìºì‹œ ì‚­ì œ

                except Exception as e:
                    logger.warning(f"   âš ï¸  ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}")

        return None

    def set(self, url: str, html: str, use_disk: bool = True) -> None:
        """
        ìºì‹œì— ë°ì´í„° ì €ì¥

        Args:
            url: ì €ì¥í•  URL
            html: ì €ì¥í•  HTML
            use_disk: ë””ìŠ¤í¬ ìºì‹œ ì‚¬ìš© ì—¬ë¶€
        """
        cache_key = self._get_cache_key(url)
        timestamp = datetime.now()

        # ë©”ëª¨ë¦¬ ìºì‹œ ì €ì¥
        with self.lock:
            self.memory_cache[cache_key] = (html, timestamp)

        # ë””ìŠ¤í¬ ìºì‹œ ì €ì¥
        if use_disk:
            try:
                cache_file = self.cache_dir / f"{cache_key}.json"
                data = {
                    "url": url,
                    "timestamp": timestamp.isoformat(),
                    "html": html,
                    "size": len(html)
                }
                with open(cache_file, 'w', encoding='utf-8') as f:
                    json.dump(data, f)
                logger.debug(f"ğŸ’¾ ë””ìŠ¤í¬ ìºì‹œ ì €ì¥: {url[:50]}... ({len(html)} bytes)")
            except Exception as e:
                logger.warning(f"   âš ï¸  ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")

    def delete(self, url: str) -> None:
        """ìºì‹œ ì‚­ì œ"""
        cache_key = self._get_cache_key(url)

        with self.lock:
            if cache_key in self.memory_cache:
                del self.memory_cache[cache_key]

        cache_file = self.cache_dir / f"{cache_key}.json"
        if cache_file.exists():
            cache_file.unlink()

    def clear(self, disk_only: bool = False) -> None:
        """ìºì‹œ ì´ˆê¸°í™”"""
        if not disk_only:
            with self.lock:
                self.memory_cache.clear()

        # ë””ìŠ¤í¬ ìºì‹œ ì‚­ì œ
        for cache_file in self.cache_dir.glob("*.json"):
            cache_file.unlink()

        logger.info("ğŸ—‘ï¸  ìºì‹œ ì´ˆê¸°í™” ì™„ë£Œ")

    def cleanup_expired(self) -> int:
        """ë§Œë£Œëœ ìºì‹œ ì •ë¦¬"""
        expired_count = 0

        # ë©”ëª¨ë¦¬ ìºì‹œ ì •ë¦¬
        with self.lock:
            expired_keys = [
                key for key, (_, ts) in self.memory_cache.items()
                if self._is_expired(ts)
            ]
            for key in expired_keys:
                del self.memory_cache[key]
            expired_count += len(expired_keys)

        # ë””ìŠ¤í¬ ìºì‹œ ì •ë¦¬
        for cache_file in self.cache_dir.glob("*.json"):
            try:
                with open(cache_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                timestamp = datetime.fromisoformat(data['timestamp'])
                if self._is_expired(timestamp):
                    cache_file.unlink()
                    expired_count += 1
            except Exception as e:
                logger.warning(f"   âš ï¸  ìºì‹œ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: {e}")

        logger.info(f"ğŸ—‘ï¸  {expired_count}ê°œì˜ ë§Œë£Œëœ ìºì‹œ ì •ë¦¬ ì™„ë£Œ")
        return expired_count

    def get_stats(self) -> Dict:
        """ìºì‹œ í†µê³„ ë°˜í™˜"""
        memory_size = sum(len(html) for html, _ in self.memory_cache.values())
        disk_size = sum(f.stat().st_size for f in self.cache_dir.glob("*.json"))

        return {
            "memory_entries": len(self.memory_cache),
            "memory_size": memory_size,
            "disk_entries": len(list(self.cache_dir.glob("*.json"))),
            "disk_size": disk_size,
            "total_size": memory_size + disk_size,
            "ttl_hours": self.ttl_hours
        }

    # ===================== ë‚´ë¶€ ë©”ì„œë“œ =====================

    def _get_cache_key(self, url: str) -> str:
        """URLì„ ìºì‹œ í‚¤ë¡œ ë³€í™˜"""
        return hashlib.md5(url.encode()).hexdigest()

    def _is_expired(self, timestamp: datetime) -> bool:
        """ìºì‹œ ë§Œë£Œ ì—¬ë¶€ í™•ì¸"""
        return datetime.now() - timestamp > timedelta(hours=self.ttl_hours)


# ===================== ì „ì—­ ìºì‹œ ì¸ìŠ¤í„´ìŠ¤ =====================

_global_cache: Optional[CacheService] = None


def get_cache_service(cache_dir: str = ".cache", ttl_hours: int = 24) -> CacheService:
    """ì „ì—­ ìºì‹œ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _global_cache
    if _global_cache is None:
        _global_cache = CacheService(cache_dir, ttl_hours)
    return _global_cache


# ===================== ì‚¬ìš© ì˜ˆì‹œ =====================

def example_cache():
    """ìºì‹œ ì„œë¹„ìŠ¤ ì˜ˆì‹œ"""
    cache = CacheService(cache_dir=".cache", ttl_hours=24)

    # ë°ì´í„° ì €ì¥
    cache.set("https://example.com/page", "<html>...</html>")

    # ë°ì´í„° ì¡°íšŒ
    html = cache.get("https://example.com/page")
    print(f"ì¡°íšŒ ê²°ê³¼: {html[:50] if html else 'ì—†ìŒ'}...")

    # í†µê³„
    stats = cache.get_stats()
    print(f"ìºì‹œ í†µê³„: {stats}")

    # ë§Œë£Œëœ ìºì‹œ ì •ë¦¬
    cache.cleanup_expired()


if __name__ == "__main__":
    example_cache()
