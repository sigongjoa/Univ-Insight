"""
ë²¡í„° ìŠ¤í† ì–´ ë° ì„ë² ë”© ì„œë¹„ìŠ¤ (Phase 3)

ì£¼ìš” ê¸°ëŠ¥:
1. ChromaDB ê¸°ë°˜ ë²¡í„° ìŠ¤í† ì–´
2. ë¬¸ì„œ ì„ë² ë”© ë° ì €ì¥
3. ì˜ë¯¸ë¡ ì  ìœ ì‚¬ë„ ê²€ìƒ‰ (semantic search)
4. ë°°ì¹˜ ì„ë² ë”© ì²˜ë¦¬
"""

import logging
import os
from typing import List, Dict, Optional, Tuple
from datetime import datetime

import chromadb
from chromadb.config import Settings

logger = logging.getLogger(__name__)


class EmbeddingService:
    """ì„ë² ë”© ì„œë¹„ìŠ¤"""

    def __init__(self, model_name: str = "sentence-transformers/all-MiniLM-L6-v2"):
        """ì´ˆê¸°í™”"""
        self.model_name = model_name
        from sentence_transformers import SentenceTransformer
        self.embedding_model = SentenceTransformer(model_name)
        logger.info(f"âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ: {model_name}")

    def embed_text(self, text: str) -> List[float]:
        """í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜"""
        embedding = self.embedding_model.encode(text)
        return embedding.tolist()

    def embed_batch(self, texts: List[str]) -> List[List[float]]:
        """ë°°ì¹˜ ì„ë² ë”©"""
        embeddings = self.embedding_model.encode(texts)
        return embeddings.tolist()


class ChromaVectorStore:
    """ChromaDB ë²¡í„° ìŠ¤í† ì–´"""

    def __init__(
        self,
        collection_name: str = "research_papers",
        persist_dir: str = "./chroma_db",
        embedding_service: Optional[EmbeddingService] = None,
    ):
        """ì´ˆê¸°í™”"""
        self.collection_name = collection_name
        self.persist_dir = persist_dir
        self.embedding_service = embedding_service or EmbeddingService()
        self.client = None
        self.collection = None
        logger.info(f"ğŸš€ ChromaVectorStore ì´ˆê¸°í™” ({collection_name})")

    async def initialize(self):
        """ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”"""
        os.makedirs(self.persist_dir, exist_ok=True)

        settings = Settings(
            chroma_db_impl="duckdb+parquet",
            persist_directory=self.persist_dir,
            anonymized_telemetry=False,
        )

        self.client = chromadb.Client(settings)
        logger.info("âœ… ChromaDB í´ë¼ì´ì–¸íŠ¸ ìƒì„±")

        self.collection = self.client.get_or_create_collection(
            name=self.collection_name,
            metadata={"hnsw:space": "cosine"}
        )

        logger.info(f"âœ… ì»¬ë ‰ì…˜ ì¤€ë¹„: {self.collection_name}")
        return True

    async def add_document(
        self,
        doc_id: str,
        content: str,
        title: str = "",
        metadata: Optional[Dict] = None,
    ) -> bool:
        """ë¬¸ì„œ ì¶”ê°€"""
        embedding = self.embedding_service.embed_text(content)

        meta = metadata or {}
        meta["title"] = title
        meta["created_at"] = datetime.now().isoformat()

        self.collection.add(
            ids=[doc_id],
            embeddings=[embedding],
            metadatas=[meta],
            documents=[content],
        )

        logger.info(f"ğŸ“ ë¬¸ì„œ ì¶”ê°€: {doc_id}")
        return True

    async def add_batch(self, documents: List[Dict]) -> int:
        """ë°°ì¹˜ ë¬¸ì„œ ì¶”ê°€"""
        ids = [doc["id"] for doc in documents]
        contents = [doc["content"] for doc in documents]

        embeddings = self.embedding_service.embed_batch(contents)

        metadatas = []
        for doc in documents:
            meta = doc.get("metadata", {})
            meta["title"] = doc.get("title", "")
            meta["created_at"] = datetime.now().isoformat()
            metadatas.append(meta)

        self.collection.add(
            ids=ids,
            embeddings=embeddings,
            metadatas=metadatas,
            documents=contents,
        )

        logger.info(f"ğŸ“¦ {len(ids)}ê°œ ë¬¸ì„œ ë°°ì¹˜ ì¶”ê°€")
        return len(ids)

    async def search(self, query: str, top_k: int = 5) -> List[Dict]:
        """ì˜ë¯¸ë¡ ì  ê²€ìƒ‰"""
        query_embedding = self.embedding_service.embed_text(query)

        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k,
        )

        search_results = []
        if results["ids"] and results["ids"][0]:
            for i, doc_id in enumerate(results["ids"][0]):
                result = {
                    "id": doc_id,
                    "content": results["documents"][0][i] if results["documents"] else "",
                    "title": results["metadatas"][0][i].get("title", "") if results["metadatas"] else "",
                    "distance": results["distances"][0][i] if results["distances"] else 0,
                    "metadata": results["metadatas"][0][i] if results["metadatas"] else {},
                }
                search_results.append(result)

        logger.info(f"ğŸ” ê²€ìƒ‰ ì™„ë£Œ: {len(search_results)}ê°œ ê²°ê³¼")
        return search_results

    async def delete_document(self, doc_id: str) -> bool:
        """ë¬¸ì„œ ì‚­ì œ"""
        self.collection.delete(ids=[doc_id])
        logger.info(f"ğŸ—‘ï¸  ë¬¸ì„œ ì‚­ì œ: {doc_id}")
        return True

    async def get_stats(self) -> Dict:
        """í†µê³„ ì¡°íšŒ"""
        count = self.collection.count()
        return {
            "collection": self.collection_name,
            "document_count": count,
            "persist_dir": self.persist_dir,
            "embedding_model": self.embedding_service.model_name,
        }

    async def clear(self) -> bool:
        """ì»¬ë ‰ì…˜ ë¹„ìš°ê¸°"""
        results = self.collection.get()
        if results["ids"]:
            self.collection.delete(ids=results["ids"])
        logger.info("ğŸ—‘ï¸  ì»¬ë ‰ì…˜ ë¹„ìš°ê¸° ì™„ë£Œ")
        return True


_vector_store_instance: Optional[ChromaVectorStore] = None


async def get_vector_store(
    collection_name: str = "research_papers",
    persist_dir: str = "./chroma_db",
) -> ChromaVectorStore:
    """ì „ì—­ ë²¡í„° ìŠ¤í† ì–´ ì¸ìŠ¤í„´ìŠ¤"""
    global _vector_store_instance
    if _vector_store_instance is None:
        _vector_store_instance = ChromaVectorStore(
            collection_name=collection_name,
            persist_dir=persist_dir,
        )
        await _vector_store_instance.initialize()
    return _vector_store_instance
