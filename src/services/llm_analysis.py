"""
LLM ë¶„ì„ ì„œë¹„ìŠ¤ (Phase 3)

ì£¼ìš” ê¸°ëŠ¥:
1. ë…¼ë¬¸ ë¶„ì„ ë° ìš”ì•½
2. ì§„ë¡œ ì—°ê²°
3. ìˆ˜í–‰í‰ê°€ ì œì•ˆ
4. êµ¬ì¡°í™”ëœ JSON ì¶œë ¥
"""

import logging
import json
import re
from typing import Dict, Optional

logger = logging.getLogger(__name__)


class LLMAnalysisService:
    """LLM ë¶„ì„ ì„œë¹„ìŠ¤"""

    def __init__(self, llm_provider: str = "ollama", model: str = "llama2"):
        """ì´ˆê¸°í™”"""
        self.llm_provider = llm_provider
        self.model = model
        logger.info(f"ðŸš€ LLMAnalysisService ì´ˆê¸°í™” ({llm_provider}/{model})")

    async def analyze_research_paper(self, rag_prompt: str) -> Dict:
        """ë…¼ë¬¸ ë¶„ì„"""
        # ì‹¤ì œ LLM í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜
        response = await self._call_llm(rag_prompt)

        # JSON íŒŒì‹±
        analysis_result = self._parse_response(response)

        logger.info("âœ… ë…¼ë¬¸ ë¶„ì„ ì™„ë£Œ")
        return analysis_result

    async def _call_llm(self, prompt: str) -> str:
        """LLM í˜¸ì¶œ"""
        if self.llm_provider == "ollama":
            return await self._call_ollama(prompt)
        elif self.llm_provider == "mock":
            return self._mock_response(prompt)
        else:
            raise ValueError(f"Unknown LLM provider: {self.llm_provider}")

    async def _call_ollama(self, prompt: str) -> str:
        """Ollama LLM í˜¸ì¶œ"""
        import subprocess

        try:
            result = subprocess.run(
                ["curl", "http://localhost:11434/api/generate"],
                input=json.dumps({
                    "model": self.model,
                    "prompt": prompt,
                    "stream": False,
                }).encode(),
                capture_output=True,
                text=True,
                timeout=60
            )

            response = json.loads(result.stdout)
            logger.info("âœ… Ollama ì‘ë‹µ ìˆ˜ì‹ ")
            return response.get("response", "")

        except Exception as e:
            logger.error(f"âŒ Ollama í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            raise

    def _mock_response(self, prompt: str) -> str:
        """ëª¨ì˜ ì‘ë‹µ"""
        return json.dumps({
            "title": "AIê°€ ì „ê¸°ë¥¼ ëœ ë¨¹ê²Œ ë§Œë“œëŠ” ë°©ë²•",
            "research": "íŠ¸ëžœìŠ¤í¬ë¨¸ ëª¨ë¸ì€ ChatGPTì˜ í•µì‹¬ ê¸°ìˆ ìž…ë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ìˆ˜ì‹­ì–µ ê°œì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ê°€ì§„ ê±°ëŒ€í•œ AI ëª¨ë¸ì„ ë” íš¨ìœ¨ì ìœ¼ë¡œ ìž‘ë™ì‹œí‚¤ëŠ” ê¸°ìˆ ì„ ì œì‹œí•©ë‹ˆë‹¤. ë§ˆì¹˜ í° ë°˜ë„ì²´ ì¹©ì´ ì „ë ¥ì„ ë§Žì´ ì†Œë¹„í•˜ëŠ” ê²ƒì²˜ëŸ¼, AI ëª¨ë¸ë„ ê³„ì‚°í•  ë•Œë§ˆë‹¤ ì—„ì²­ë‚œ ì—ë„ˆì§€ë¥¼ ì¨ìš”. ì´ ì—°êµ¬ëŠ” ê·¸ ì—ë„ˆì§€ë¥¼ ì¤„ì´ë©´ì„œë„ ì„±ëŠ¥ì€ ìœ ì§€í•˜ëŠ” ë°©ë²•ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.",
            "career_paths": [
                "NVIDIA - AI ì¹© ì„¤ê³„ ì—”ì§€ë‹ˆì–´ - 1.2ì–µì›",
                "ì‚¼ì„±ì „ìž - AI ìµœì í™” ì—°êµ¬ì› - 1ì–µì›",
                "Google - Machine Learning Engineer - 1.5ì–µì›"
            ],
            "action_items": [
                "ìˆ˜í•™(ì„ í˜•ëŒ€ìˆ˜, ë¯¸ì ë¶„)",
                "ë¬¼ë¦¬(ì—ë„ˆì§€, íš¨ìœ¨)",
                "ìˆ˜í–‰í‰ê°€: 'ìƒí™œ ì† AIì˜ ì „ë ¥ì†Œë¹„ ë¶„ì„'"
            ]
        })

    def _parse_response(self, response: str) -> Dict:
        """ì‘ë‹µ íŒŒì‹±"""
        if not response:
            logger.warning("âš ï¸  ë¹ˆ ì‘ë‹µ")
            return {}

        # JSON ì¶”ì¶œ ì‹œë„
        json_match = re.search(r'\{.*\}', response, re.DOTALL)
        if json_match:
            json_str = json_match.group(0)
            return json.loads(json_str)

        logger.warning("âš ï¸  JSON íŒŒì‹± ì‹¤íŒ¨")
        return {
            "raw_response": response,
            "parse_error": True
        }

    async def extract_career_paths(self, analysis: Dict) -> list:
        """ì§„ë¡œ ì •ë³´ ì¶”ì¶œ"""
        career_paths = analysis.get("career_paths", [])
        logger.info(f"ðŸ“Š {len(career_paths)}ê°œ ì§„ë¡œ ì¶”ì¶œ")
        return career_paths

    async def extract_action_items(self, analysis: Dict) -> list:
        """ì‹¤í–‰ í•­ëª© ì¶”ì¶œ"""
        action_items = analysis.get("action_items", [])
        logger.info(f"ðŸ“‹ {len(action_items)}ê°œ ì‹¤í–‰í•­ëª© ì¶”ì¶œ")
        return action_items

    async def get_stats(self) -> Dict:
        """í†µê³„ ì¡°íšŒ"""
        return {
            "llm_provider": self.llm_provider,
            "model": self.model,
            "status": "operational",
        }
