"""
Redis ê¸°ë°˜ ë¶„ì‚° ì‘ì—… í

ì£¼ìš” ê¸°ëŠ¥:
1. ë‹¤ì¤‘ ë¨¸ì‹  ê°„ ì‘ì—… ê³µìœ 
2. ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ìŠ¤ì¼€ì¤„ë§
3. ì‘ì—… ìƒíƒœ ì¤‘ì•™ ê´€ë¦¬
4. ìë™ ì¬ì‹œë„ ë° ì‹¤íŒ¨ ì²˜ë¦¬
"""

import json
import logging
import hashlib
from typing import Optional, Dict, List
from datetime import datetime, timedelta
import asyncio

try:
    import aioredis
    from aioredis import Redis
    REDIS_AVAILABLE = True
except ImportError:
    REDIS_AVAILABLE = False
    logging.warning("âš ï¸  aioredis ë¯¸ì„¤ì¹˜ - Redis ê¸°ëŠ¥ ì‚¬ìš© ë¶ˆê°€")

from src.services.task_queue import CrawlTask, TaskStatus, TaskPriority

logger = logging.getLogger(__name__)


class RedisTaskQueue:
    """Redis ê¸°ë°˜ ë¶„ì‚° ì‘ì—… í"""

    def __init__(
        self,
        redis_url: str = "redis://localhost:6379/0",
        ttl_hours: int = 24,
        fallback_to_memory: bool = True
    ):
        """
        ì´ˆê¸°í™”

        Args:
            redis_url: Redis ì—°ê²° URL
            ttl_hours: ì‘ì—… TTL (ì‹œê°„)
            fallback_to_memory: Redis ë¯¸ì—°ê²° ì‹œ ë©”ëª¨ë¦¬ í´ë°±
        """
        self.redis_url = redis_url
        self.ttl_hours = ttl_hours
        self.fallback_to_memory = fallback_to_memory
        self.redis: Optional[Redis] = None
        self.memory_fallback = {} if fallback_to_memory else None

        # Redis í‚¤ í”„ë¦¬í”½ìŠ¤
        self.prefix = "crawl:"
        self.queue_key = f"{self.prefix}queue"
        self.task_key = f"{self.prefix}task:"
        self.result_key = f"{self.prefix}result:"

        logger.info(f"ğŸš€ RedisTaskQueue ì´ˆê¸°í™” ({redis_url})")

    async def connect(self):
        """Redis ì—°ê²°"""
        if not REDIS_AVAILABLE:
            logger.warning("âš ï¸  Redis ì‚¬ìš© ë¶ˆê°€ - ë©”ëª¨ë¦¬ ëª¨ë“œë¡œ í´ë°±")
            return

        try:
            self.redis = await aioredis.create_redis_pool(self.redis_url)
            logger.info("âœ… Redis ì—°ê²° ì„±ê³µ")
        except Exception as e:
            logger.error(f"âŒ Redis ì—°ê²° ì‹¤íŒ¨: {e}")
            if self.fallback_to_memory:
                logger.warning("âš ï¸  ë©”ëª¨ë¦¬ ëª¨ë“œë¡œ í´ë°±")
            else:
                raise

    async def disconnect(self):
        """Redis ì—°ê²° í•´ì œ"""
        if self.redis:
            self.redis.close()
            await self.redis.wait_closed()
            logger.info("âœ… Redis ì—°ê²° í•´ì œ")

    async def enqueue(self, task: CrawlTask) -> str:
        """ì‘ì—… íì— ì¶”ê°€"""
        task_json = self._serialize_task(task)

        if self.redis:
            try:
                # ì‘ì—… ì €ì¥
                await self.redis.set(
                    f"{self.task_key}{task.task_id}",
                    task_json,
                    expire=int(self.ttl_hours * 3600)
                )

                # ìš°ì„ ìˆœìœ„ íì— ì¶”ê°€
                await self.redis.zadd(
                    self.queue_key,
                    -task.priority,  # ìŒìˆ˜ë¡œ í•˜ë©´ ë†’ì€ ìš°ì„ ìˆœìœ„ ë¨¼ì €
                    task.task_id
                )

                logger.info(f"ğŸ“ ì‘ì—… ì¶”ê°€ (Redis): {task.task_id[:8]}...")
                return task.task_id

            except Exception as e:
                logger.error(f"âŒ Redis ì €ì¥ ì‹¤íŒ¨: {e}")
                if self.fallback_to_memory:
                    return self._enqueue_memory(task, task_json)
                raise
        else:
            return self._enqueue_memory(task, task_json)

    def _enqueue_memory(self, task: CrawlTask, task_json: str) -> str:
        """ë©”ëª¨ë¦¬ì— ì‘ì—… ì €ì¥ (í´ë°±)"""
        self.memory_fallback[task.task_id] = {
            "task": task,
            "json": task_json,
            "priority": -task.priority
        }
        logger.info(f"ğŸ“ ì‘ì—… ì¶”ê°€ (ë©”ëª¨ë¦¬): {task.task_id[:8]}...")
        return task.task_id

    async def dequeue(self, worker_id: str = "default") -> Optional[CrawlTask]:
        """ë‹¤ìŒ ì‘ì—… íšë“"""
        if self.redis:
            try:
                # ìš°ì„ ìˆœìœ„ ê°€ì¥ ë†’ì€ ì‘ì—… íšë“
                result = await self.redis.zrange(self.queue_key, 0, 0)
                if not result:
                    return None

                task_id = result[0].decode() if isinstance(result[0], bytes) else result[0]

                # ì‘ì—… ë¡œë“œ
                task_json = await self.redis.get(f"{self.task_key}{task_id}")
                if not task_json:
                    # íì—ì„œ ì œê±°
                    await self.redis.zrem(self.queue_key, task_id)
                    return None

                task = self._deserialize_task(task_json)
                task.status = TaskStatus.RUNNING.value

                # ì›Œì»¤ ì •ë³´ ì €ì¥
                await self.redis.hset(
                    f"{self.prefix}running:{task_id}",
                    "worker_id", worker_id,
                    "started_at", datetime.now().isoformat()
                )

                # íì—ì„œ ì œê±°
                await self.redis.zrem(self.queue_key, task_id)

                logger.info(f"ğŸƒ ì‘ì—… ì‹œì‘: {task_id[:8]}... (ì›Œì»¤: {worker_id})")
                return task

            except Exception as e:
                logger.error(f"âŒ Redis ì‘ì—… íšë“ ì‹¤íŒ¨: {e}")
                if self.fallback_to_memory:
                    return self._dequeue_memory()
                return None
        else:
            return self._dequeue_memory()

    def _dequeue_memory(self) -> Optional[CrawlTask]:
        """ë©”ëª¨ë¦¬ì—ì„œ ì‘ì—… íšë“ (í´ë°±)"""
        if not self.memory_fallback:
            return None

        # ìš°ì„ ìˆœìœ„ ê°€ì¥ ë†’ì€ ì‘ì—… ì°¾ê¸°
        best_task_id = min(
            self.memory_fallback.keys(),
            key=lambda k: self.memory_fallback[k]["priority"]
        )

        task = self.memory_fallback[best_task_id]["task"]
        del self.memory_fallback[best_task_id]

        return task

    async def mark_completed(self, task_id: str) -> bool:
        """ì‘ì—… ì™„ë£Œ í‘œì‹œ"""
        if self.redis:
            try:
                await self.redis.set(
                    f"{self.prefix}completed:{task_id}",
                    datetime.now().isoformat(),
                    expire=int(self.ttl_hours * 3600)
                )
                await self.redis.delete(f"{self.prefix}running:{task_id}")
                await self.redis.delete(f"{self.task_key}{task_id}")
                logger.info(f"âœ… ì‘ì—… ì™„ë£Œ: {task_id[:8]}...")
                return True
            except Exception as e:
                logger.error(f"âŒ ì‘ì—… ì™„ë£Œ í‘œì‹œ ì‹¤íŒ¨: {e}")
                return False
        return True

    async def mark_failed(self, task_id: str, error: str = "") -> bool:
        """ì‘ì—… ì‹¤íŒ¨ í‘œì‹œ"""
        if self.redis:
            try:
                await self.redis.hset(
                    f"{self.prefix}failed:{task_id}",
                    "error", error,
                    "timestamp", datetime.now().isoformat()
                )
                await self.redis.delete(f"{self.prefix}running:{task_id}")
                logger.error(f"âŒ ì‘ì—… ì‹¤íŒ¨: {task_id[:8]}... {error}")
                return True
            except Exception as e:
                logger.error(f"âŒ ì‘ì—… ì‹¤íŒ¨ í‘œì‹œ ì‹¤íŒ¨: {e}")
                return False
        return True

    async def get_task_status(self, task_id: str) -> Optional[str]:
        """ì‘ì—… ìƒíƒœ ì¡°íšŒ"""
        if self.redis:
            try:
                # ì‹¤í–‰ ì¤‘ í™•ì¸
                if await self.redis.exists(f"{self.prefix}running:{task_id}"):
                    return TaskStatus.RUNNING.value

                # ì™„ë£Œ í™•ì¸
                if await self.redis.exists(f"{self.prefix}completed:{task_id}"):
                    return TaskStatus.COMPLETED.value

                # ì‹¤íŒ¨ í™•ì¸
                if await self.redis.exists(f"{self.prefix}failed:{task_id}"):
                    return TaskStatus.FAILED.value

                # íì— ìˆëŠ”ì§€ í™•ì¸
                if await self.redis.zrank(self.queue_key, task_id) is not None:
                    return TaskStatus.PENDING.value

                return None

            except Exception as e:
                logger.error(f"âŒ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
                return None
        return None

    async def get_stats(self) -> Dict:
        """í í†µê³„"""
        if self.redis:
            try:
                pending = await self.redis.zcard(self.queue_key)
                running = await self.redis.dbsize()  # ê·¼ì‚¬ê°’
                return {
                    "pending": pending,
                    "running": running,
                    "completed": 0,  # ì¶”ì  í•„ìš”
                    "failed": 0,      # ì¶”ì  í•„ìš”
                    "total": pending + running,
                }
            except Exception as e:
                logger.error(f"âŒ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
                return {"error": str(e)}
        return {}

    async def health_check(self) -> Dict:
        """ê±´ê°• ìƒíƒœ í™•ì¸"""
        if not self.redis:
            return {
                "status": "unhealthy",
                "reason": "Redis not available"
            }

        try:
            await self.redis.ping()
            return {
                "status": "healthy",
                "redis_connected": True,
            }
        except Exception as e:
            return {
                "status": "unhealthy",
                "redis_connected": False,
                "error": str(e)
            }

    def _serialize_task(self, task: CrawlTask) -> str:
        """ì‘ì—…ì„ JSONìœ¼ë¡œ ì§ë ¬í™”"""
        return json.dumps({
            "task_id": task.task_id,
            "url": task.url,
            "university_name": task.university_name,
            "department_name": task.department_name,
            "priority": task.priority,
            "created_at": task.created_at.isoformat(),
            "status": task.status,
            "retry_count": task.retry_count,
            "max_retries": task.max_retries,
            "use_cache": task.use_cache,
            "use_ocr": task.use_ocr,
            "parallel_crawl": task.parallel_crawl,
            "timeout_seconds": task.timeout_seconds,
        })

    def _deserialize_task(self, task_json) -> CrawlTask:
        """JSONì—ì„œ ì‘ì—…ìœ¼ë¡œ ì—­ì§ë ¬í™”"""
        if isinstance(task_json, bytes):
            task_json = task_json.decode()

        data = json.loads(task_json)

        return CrawlTask(
            url=data["url"],
            university_name=data["university_name"],
            department_name=data.get("department_name", ""),
            priority=data.get("priority", 0),
            task_id=data["task_id"],
            status=data.get("status", TaskStatus.PENDING.value),
            retry_count=data.get("retry_count", 0),
            max_retries=data.get("max_retries", 3),
            use_cache=data.get("use_cache", True),
            use_ocr=data.get("use_ocr", False),
            parallel_crawl=data.get("parallel_crawl", False),
            timeout_seconds=data.get("timeout_seconds", 30),
        )


# ì „ì—­ Redis í ì¸ìŠ¤í„´ìŠ¤
_redis_queue_instance: Optional[RedisTaskQueue] = None


async def get_redis_queue(redis_url: str = None) -> RedisTaskQueue:
    """ì „ì—­ Redis í ì¸ìŠ¤í„´ìŠ¤"""
    global _redis_queue_instance
    if _redis_queue_instance is None:
        _redis_queue_instance = RedisTaskQueue(
            redis_url=redis_url or "redis://localhost:6379/0"
        )
        await _redis_queue_instance.connect()
    return _redis_queue_instance
